{"message": {"transcript": [{"chunks": [{"end": 0.6, "start": 0.0, "text": "Sure."}, {"end": 1.12, "start": 0.6, "text": "Thanks,"}, {"end": 1.88, "start": 1.12, "text": "Matthias,"}, {"end": 2.12, "start": 1.88, "text": "for"}, {"end": 2.4, "start": 2.12, "text": "the"}, {"end": 3.28, "start": 2.4, "text": "introduction."}, {"end": 3.72, "start": 3.28, "text": "Good"}, {"end": 4.16, "start": 3.72, "text": "afternoon,"}, {"end": 4.68, "start": 4.16, "text": "everyone."}, {"end": 5.08, "start": 4.68, "text": "I'm"}, {"end": 6.08, "start": 5.08, "text": "from"}, {"end": 6.88, "start": 6.08, "text": "HKST."}, {"end": 7.36, "start": 6.88, "text": "So"}, {"end": 7.8, "start": 7.36, "text": "I"}, {"end": 7.92, "start": 7.8, "text": "will"}, {"end": 7.96, "start": 7.92, "text": "be"}, {"end": 8.68, "start": 7.96, "text": "presenting"}, {"end": 8.8, "start": 8.68, "text": "the"}, {"end": 9.2, "start": 8.8, "text": "paper"}, {"end": 9.6, "start": 9.2, "text": "mentioned"}, {"end": 9.84, "start": 9.6, "text": "by"}, {"end": 10.36, "start": 9.84, "text": "Mario"}, {"end": 10.44, "start": 10.36, "text": "in"}, {"end": 10.72, "start": 10.44, "text": "his"}, {"end": 11.28, "start": 10.72, "text": "keynote"}, {"end": 11.6, "start": 11.28, "text": "this"}, {"end": 12.0, "start": 11.6, "text": "morning."}, {"end": 12.4, "start": 12.0, "text": "So"}, {"end": 13.2, "start": 12.4, "text": "actually,"}, {"end": 13.24, "start": 13.2, "text": "in"}, {"end": 13.44, "start": 13.24, "text": "this"}, {"end": 13.6, "start": 13.44, "text": "paper,"}, {"end": 13.68, "start": 13.6, "text": "we"}, {"end": 14.12, "start": 13.68, "text": "are"}, {"end": 14.36, "start": 14.12, "text": "talking"}, {"end": 14.8, "start": 14.36, "text": "about"}, {"end": 15.04, "start": 14.8, "text": "a"}, {"end": 15.64, "start": 15.04, "text": "time"}, {"end": 16.12, "start": 15.64, "text": "series"}, {"end": 16.52, "start": 16.12, "text": "foundation"}, {"end": 17.28, "start": 16.52, "text": "models"}, {"end": 17.6, "start": 17.28, "text": "ready"}, {"end": 17.8, "start": 17.6, "text": "to"}, {"end": 18.72, "start": 17.8, "text": "revolutionize"}, {"end": 19.36, "start": 18.72, "text": "predictive"}, {"end": 19.76, "start": 19.36, "text": "building"}, {"end": 20.36, "start": 19.76, "text": "analytics."}, {"end": 20.36, "start": 20.36, "text": "So"}, {"end": 21.12, "start": 20.36, "text": "this"}, {"end": 21.8, "start": 21.12, "text": "work"}, {"end": 22.36, "start": 21.8, "text": "is"}, {"end": 22.44, "start": 22.36, "text": "a"}, {"end": 22.88, "start": 22.44, "text": "joint"}, {"end": 23.36, "start": 22.88, "text": "work"}, {"end": 24.08, "start": 23.36, "text": "with"}, {"end": 24.28, "start": 24.08, "text": "Oden,"}, {"end": 24.88, "start": 24.28, "text": "Peng"}, {"end": 25.28, "start": 24.88, "text": "Rui,"}, {"end": 26.24, "start": 25.28, "text": "Liying,"}, {"end": 26.64, "start": 26.24, "text": "Dezhi,"}, {"end": 26.88, "start": 26.64, "text": "Mario,"}, {"end": 27.16, "start": 26.88, "text": "and"}, {"end": 27.52, "start": 27.16, "text": "Mani,"}, {"end": 27.76, "start": 27.52, "text": "why"}, {"end": 28.04, "start": 27.76, "text": "was"}, {"end": 28.04, "start": 28.04, "text": "a"}, {"end": 28.36, "start": 28.04, "text": "poster"}, {"end": 28.6, "start": 28.36, "text": "at"}, {"end": 29.96, "start": 28.6, "text": "UCLA?"}], "text": " Sure. Thanks, Matthias, for the introduction. Good afternoon, everyone. I'm from HKST. So I will be presenting the paper mentioned by Mario in his keynote this morning. So actually, in this paper, we are talking about a time series foundation models ready to revolutionize predictive building analytics. So this work is a joint work with Oden, Peng Rui, Liying, Dezhi, Mario, and Mani, why was a poster at UCLA?"}, {"chunks": [{"end": 31.12, "start": 30.0, "text": "So,"}, {"end": 32.4, "start": 31.12, "text": "just"}, {"end": 32.92, "start": 32.4, "text": "mentioned"}, {"end": 33.08, "start": 32.92, "text": "by"}, {"end": 33.32, "start": 33.08, "text": "the"}, {"end": 33.88, "start": 33.32, "text": "previous"}, {"end": 34.08, "start": 33.88, "text": "speaker,"}, {"end": 34.480000000000004, "start": 34.08, "text": "so"}, {"end": 34.6, "start": 34.480000000000004, "text": "in"}, {"end": 35.32, "start": 34.6, "text": "building"}, {"end": 36.24, "start": 35.32, "text": "analytics,"}, {"end": 36.76, "start": 36.24, "text": "actually"}, {"end": 37.56, "start": 36.76, "text": "forecasting"}, {"end": 37.8, "start": 37.56, "text": "key"}, {"end": 38.4, "start": 37.8, "text": "metrics"}, {"end": 38.72, "start": 38.4, "text": "such"}, {"end": 38.88, "start": 38.72, "text": "as"}, {"end": 39.2, "start": 38.88, "text": "energy"}, {"end": 40.08, "start": 39.2, "text": "consumption"}, {"end": 40.36, "start": 40.08, "text": "or"}, {"end": 40.36, "start": 40.36, "text": "in"}, {"end": 40.44, "start": 40.36, "text": "the"}, {"end": 41.32, "start": 40.44, "text": "temperature"}, {"end": 41.480000000000004, "start": 41.32, "text": "is"}, {"end": 41.8, "start": 41.480000000000004, "text": "very"}, {"end": 42.92, "start": 41.8, "text": "important."}, {"end": 43.28, "start": 42.92, "text": "So,"}, {"end": 43.6, "start": 43.28, "text": "for"}, {"end": 44.08, "start": 43.6, "text": "example,"}, {"end": 44.56, "start": 44.08, "text": "suppose"}, {"end": 44.64, "start": 44.56, "text": "if"}, {"end": 44.84, "start": 44.64, "text": "we"}, {"end": 45.44, "start": 44.84, "text": "have"}, {"end": 45.92, "start": 45.44, "text": "84"}, {"end": 46.56, "start": 45.92, "text": "hours"}, {"end": 46.68, "start": 46.56, "text": "of"}, {"end": 46.879999999999995, "start": 46.68, "text": "energy"}, {"end": 47.36, "start": 46.879999999999995, "text": "usage"}, {"end": 47.92, "start": 47.36, "text": "data,"}, {"end": 48.44, "start": 47.92, "text": "then"}, {"end": 49.2, "start": 48.44, "text": "how"}, {"end": 49.96, "start": 49.2, "text": "can"}, {"end": 50.120000000000005, "start": 49.96, "text": "we"}, {"end": 50.28, "start": 50.120000000000005, "text": "predict"}, {"end": 50.879999999999995, "start": 50.28, "text": "the"}, {"end": 51.120000000000005, "start": 50.879999999999995, "text": "energy"}, {"end": 51.92, "start": 51.120000000000005, "text": "consumption"}, {"end": 51.96, "start": 51.92, "text": "in"}, {"end": 52.120000000000005, "start": 51.96, "text": "the"}, {"end": 52.56, "start": 52.120000000000005, "text": "next"}, {"end": 52.96, "start": 52.56, "text": "12"}, {"end": 55.28, "start": 52.96, "text": "hours?"}, {"end": 55.68, "start": 55.28, "text": "So,"}, {"end": 56.239999999999995, "start": 55.68, "text": "first,"}, {"end": 56.32, "start": 56.239999999999995, "text": "we"}, {"end": 56.8, "start": 56.32, "text": "humans"}, {"end": 56.92, "start": 56.8, "text": "can"}, {"end": 57.519999999999996, "start": 56.92, "text": "predict"}, {"end": 57.64, "start": 57.519999999999996, "text": "the"}, {"end": 58.32, "start": 57.64, "text": "tendency"}, {"end": 58.480000000000004, "start": 58.32, "text": "of"}, {"end": 58.8, "start": 58.480000000000004, "text": "the"}, {"end": 59.0, "start": 58.8, "text": "energy"}, {"end": 59.480000000000004, "start": 59.0, "text": "usage"}, {"end": 59.56, "start": 59.480000000000004, "text": "by"}, {"end": 59.96, "start": 59.56, "text": "ourselves."}], "text": " So, just mentioned by the previous speaker, so in building analytics, actually forecasting key metrics such as energy consumption or in the temperature is very important. So, for example, suppose if we have 84 hours of energy usage data, then how can we predict the energy consumption in the next 12 hours? So, first, we humans can predict the tendency of the energy usage by ourselves."}, {"chunks": [{"end": 60.36, "start": 60.0, "text": "based"}, {"end": 61.0, "start": 60.36, "text": "on"}, {"end": 61.32, "start": 61.0, "text": "our"}, {"end": 61.84, "start": 61.32, "text": "domain"}, {"end": 62.28, "start": 61.84, "text": "knowledge."}, {"end": 62.4, "start": 62.28, "text": "And"}, {"end": 63.96, "start": 62.4, "text": "we"}, {"end": 64.52, "start": 63.96, "text": "can"}, {"end": 64.92, "start": 64.52, "text": "also"}, {"end": 65.28, "start": 64.92, "text": "train"}, {"end": 65.68, "start": 65.28, "text": "machine"}, {"end": 65.92, "start": 65.68, "text": "learning"}, {"end": 66.16, "start": 65.92, "text": "models"}, {"end": 66.36, "start": 66.16, "text": "to"}, {"end": 66.96, "start": 66.36, "text": "forecast"}, {"end": 67.32, "start": 66.96, "text": "this"}, {"end": 67.6, "start": 67.32, "text": "time"}, {"end": 67.92, "start": 67.6, "text": "series"}, {"end": 68.16, "start": 67.92, "text": "data."}, {"end": 69.48, "start": 68.16, "text": "And"}, {"end": 69.84, "start": 69.48, "text": "these"}, {"end": 70.32, "start": 69.84, "text": "days"}, {"end": 70.6, "start": 70.32, "text": "you"}, {"end": 70.88, "start": 70.6, "text": "might"}, {"end": 71.8, "start": 70.88, "text": "also"}, {"end": 72.08, "start": 71.8, "text": "think"}, {"end": 72.44, "start": 72.08, "text": "that"}, {"end": 73.0, "start": 72.44, "text": "foundation"}, {"end": 73.56, "start": 73.0, "text": "models"}, {"end": 73.76, "start": 73.56, "text": "might"}, {"end": 74.44, "start": 73.76, "text": "provide"}, {"end": 75.16, "start": 74.44, "text": "also"}, {"end": 75.28, "start": 75.16, "text": "an"}, {"end": 75.68, "start": 75.28, "text": "effective"}, {"end": 79.64, "start": 75.68, "text": "solution."}, {"end": 80.36, "start": 79.64, "text": "So"}, {"end": 81.08, "start": 80.36, "text": "recently"}, {"end": 81.56, "start": 81.08, "text": "foundation"}, {"end": 82.12, "start": 81.56, "text": "models"}, {"end": 82.2, "start": 82.12, "text": "have"}, {"end": 82.52, "start": 82.2, "text": "gained"}, {"end": 82.88, "start": 82.52, "text": "lots"}, {"end": 83.0, "start": 82.88, "text": "of"}, {"end": 83.8, "start": 83.0, "text": "attention"}, {"end": 84.12, "start": 83.8, "text": "due"}, {"end": 84.44, "start": 84.12, "text": "to"}, {"end": 84.64, "start": 84.44, "text": "their"}, {"end": 85.24, "start": 84.64, "text": "success"}, {"end": 85.4, "start": 85.24, "text": "in"}, {"end": 85.72, "start": 85.4, "text": "language"}, {"end": 86.32, "start": 85.72, "text": "tax."}, {"end": 86.32, "start": 86.32, "text": "And"}, {"end": 86.76, "start": 86.32, "text": "here"}, {"end": 87.48, "start": 86.76, "text": "we"}, {"end": 87.64, "start": 87.48, "text": "are"}, {"end": 88.16, "start": 87.64, "text": "discussing"}, {"end": 88.4, "start": 88.16, "text": "a"}, {"end": 88.76, "start": 88.4, "text": "broader"}, {"end": 89.24, "start": 88.76, "text": "concept"}, {"end": 89.44, "start": 89.24, "text": "of"}, {"end": 89.96000000000001, "start": 89.44, "text": "foundation"}], "text": " based on our domain knowledge. And we can also train machine learning models to forecast this time series data. And these days you might also think that foundation models might provide also an effective solution. So recently foundation models have gained lots of attention due to their success in language tax. And here we are discussing a broader concept of foundation"}, {"chunks": [{"end": 90.52, "start": 90.0, "text": "models,"}, {"end": 90.8, "start": 90.52, "text": "including"}, {"end": 90.92, "start": 90.8, "text": "both"}, {"end": 91.08, "start": 90.92, "text": "large"}, {"end": 91.28, "start": 91.08, "text": "language"}, {"end": 91.72, "start": 91.28, "text": "models"}, {"end": 92.08, "start": 91.72, "text": "as"}, {"end": 92.32, "start": 92.08, "text": "well"}, {"end": 92.92, "start": 92.32, "text": "as"}, {"end": 93.44, "start": 92.92, "text": "models"}, {"end": 94.04, "start": 93.44, "text": "that"}, {"end": 94.2, "start": 94.04, "text": "can"}, {"end": 94.92, "start": 94.2, "text": "process"}, {"end": 95.16, "start": 94.92, "text": "other"}, {"end": 95.52, "start": 95.16, "text": "data"}, {"end": 97.68, "start": 95.52, "text": "modalities."}, {"end": 98.12, "start": 97.68, "text": "So"}, {"end": 98.72, "start": 98.12, "text": "the"}, {"end": 99.0, "start": 98.72, "text": "key"}, {"end": 99.68, "start": 99.0, "text": "advantage"}, {"end": 99.84, "start": 99.68, "text": "of"}, {"end": 100.16, "start": 99.84, "text": "foundation"}, {"end": 100.84, "start": 100.16, "text": "models"}, {"end": 101.08, "start": 100.84, "text": "is"}, {"end": 101.52, "start": 101.08, "text": "their"}, {"end": 101.84, "start": 101.52, "text": "strong"}, {"end": 102.44, "start": 101.84, "text": "generalization"}, {"end": 103.48, "start": 102.44, "text": "capabilities,"}, {"end": 103.96000000000001, "start": 103.48, "text": "which"}, {"end": 104.44, "start": 103.96000000000001, "text": "means"}, {"end": 104.56, "start": 104.44, "text": "they"}, {"end": 104.92, "start": 104.56, "text": "can"}, {"end": 105.48, "start": 104.92, "text": "perform"}, {"end": 106.44, "start": 105.48, "text": "zero-shot"}, {"end": 107.08, "start": 106.44, "text": "prediction"}, {"end": 107.6, "start": 107.08, "text": "without"}, {"end": 108.44, "start": 107.6, "text": "domain-specific"}, {"end": 110.72, "start": 108.44, "text": "training."}, {"end": 111.44, "start": 110.72, "text": "And"}, {"end": 111.68, "start": 111.44, "text": "in"}, {"end": 111.84, "start": 111.68, "text": "addition"}, {"end": 112.2, "start": 111.84, "text": "to"}, {"end": 112.8, "start": 112.2, "text": "large"}, {"end": 113.44, "start": 112.8, "text": "language"}, {"end": 114.12, "start": 113.44, "text": "models,"}, {"end": 114.72, "start": 114.12, "text": "recently"}, {"end": 115.24, "start": 114.72, "text": "researchers"}, {"end": 115.44, "start": 115.24, "text": "are"}, {"end": 115.76, "start": 115.44, "text": "now"}, {"end": 116.32, "start": 115.76, "text": "also"}, {"end": 116.84, "start": 116.32, "text": "exploring"}, {"end": 117.24, "start": 116.84, "text": "time"}, {"end": 117.6, "start": 117.24, "text": "series"}, {"end": 118.08, "start": 117.6, "text": "foundation"}, {"end": 118.68, "start": 118.08, "text": "models,"}, {"end": 118.76, "start": 118.68, "text": "or"}, {"end": 118.76, "start": 118.76, "text": "we"}, {"end": 119.2, "start": 118.76, "text": "call"}, {"end": 119.48, "start": 119.2, "text": "it"}, {"end": 119.96000000000001, "start": 119.48, "text": "TSF"}], "text": " models, including both large language models as well as models that can process other data modalities. So the key advantage of foundation models is their strong generalization capabilities, which means they can perform zero-shot prediction without domain-specific training. And in addition to large language models, recently researchers are now also exploring time series foundation models, or we call it TSF"}, {"chunks": [{"end": 120.4, "start": 120.0, "text": "and"}, {"end": 120.8, "start": 120.4, "text": "we"}, {"end": 121.24, "start": 120.8, "text": "think"}, {"end": 121.72, "start": 121.24, "text": "that"}, {"end": 122.2, "start": 121.72, "text": "these"}, {"end": 122.68, "start": 122.2, "text": "models"}, {"end": 122.88, "start": 122.68, "text": "may"}, {"end": 122.96, "start": 122.88, "text": "be"}, {"end": 123.48, "start": 122.96, "text": "also"}, {"end": 124.04, "start": 123.48, "text": "particularly"}, {"end": 124.68, "start": 124.04, "text": "suited"}, {"end": 124.88, "start": 124.68, "text": "for"}, {"end": 125.24, "start": 124.88, "text": "time"}, {"end": 125.48, "start": 125.24, "text": "series"}, {"end": 126.08, "start": 125.48, "text": "data"}, {"end": 126.28, "start": 126.08, "text": "in"}, {"end": 126.64, "start": 126.28, "text": "building"}, {"end": 128.76, "start": 126.64, "text": "analytics."}, {"end": 129.04, "start": 128.76, "text": "However,"}, {"end": 129.48, "start": 129.04, "text": "we"}, {"end": 130.04, "start": 129.48, "text": "found"}, {"end": 130.48, "start": 130.04, "text": "that"}, {"end": 130.52, "start": 130.48, "text": "there"}, {"end": 130.84, "start": 130.52, "text": "was"}, {"end": 131.04, "start": 130.84, "text": "no"}, {"end": 132.0, "start": 131.04, "text": "comprehensive"}, {"end": 132.88, "start": 132.0, "text": "evaluations"}, {"end": 133.0, "start": 132.88, "text": "on"}, {"end": 133.04, "start": 133.0, "text": "the"}, {"end": 134.28, "start": 133.04, "text": "readiness"}, {"end": 134.44, "start": 134.28, "text": "of"}, {"end": 134.76, "start": 134.44, "text": "these"}, {"end": 135.08, "start": 134.76, "text": "time"}, {"end": 135.36, "start": 135.08, "text": "series"}, {"end": 135.88, "start": 135.36, "text": "foundation"}, {"end": 136.44, "start": 135.88, "text": "models"}, {"end": 136.76, "start": 136.44, "text": "for"}, {"end": 137.07999999999998, "start": 136.76, "text": "building"}, {"end": 138.36, "start": 137.07999999999998, "text": "analytics."}, {"end": 138.76, "start": 138.36, "text": "So"}, {"end": 138.84, "start": 138.76, "text": "in"}, {"end": 139.07999999999998, "start": 138.84, "text": "this"}, {"end": 139.4, "start": 139.07999999999998, "text": "work,"}, {"end": 139.44, "start": 139.4, "text": "we"}, {"end": 139.72, "start": 139.44, "text": "aim"}, {"end": 140.36, "start": 139.72, "text": "to"}, {"end": 140.88, "start": 140.36, "text": "assess"}, {"end": 141.8, "start": 140.88, "text": "how"}, {"end": 141.84, "start": 141.8, "text": "we"}, {"end": 142.07999999999998, "start": 141.84, "text": "are"}, {"end": 142.36, "start": 142.07999999999998, "text": "at"}, {"end": 142.52, "start": 142.36, "text": "that"}, {"end": 145.16, "start": 142.52, "text": "point."}, {"end": 145.56, "start": 145.16, "text": "And"}, {"end": 145.84, "start": 145.56, "text": "you"}, {"end": 146.32, "start": 145.84, "text": "might"}, {"end": 146.72, "start": 146.32, "text": "have"}, {"end": 147.0, "start": 146.72, "text": "been"}, {"end": 147.4, "start": 147.0, "text": "sleeping"}, {"end": 147.68, "start": 147.4, "text": "now,"}, {"end": 147.76, "start": 147.68, "text": "but"}, {"end": 148.07999999999998, "start": 147.76, "text": "let"}, {"end": 148.16, "start": 148.07999999999998, "text": "me"}, {"end": 148.32, "start": 148.16, "text": "show"}, {"end": 148.84, "start": 148.32, "text": "you"}, {"end": 149.28, "start": 148.84, "text": "some"}, {"end": 149.96, "start": 149.28, "text": "examples."}], "text": " and we think that these models may be also particularly suited for time series data in building analytics. However, we found that there was no comprehensive evaluations on the readiness of these time series foundation models for building analytics. So in this work, we aim to assess how we are at that point. And you might have been sleeping now, but let me show you some examples."}, {"chunks": [{"end": 151.08, "start": 150.0, "text": "So"}, {"end": 151.8, "start": 151.08, "text": "basically,"}, {"end": 152.08, "start": 151.8, "text": "just"}, {"end": 152.2, "start": 152.08, "text": "in"}, {"end": 152.4, "start": 152.2, "text": "the"}, {"end": 153.0, "start": 152.4, "text": "past"}, {"end": 153.4, "start": 153.0, "text": "years,"}, {"end": 153.68, "start": 153.4, "text": "we"}, {"end": 153.96, "start": 153.68, "text": "have"}, {"end": 154.4, "start": 153.96, "text": "seen"}, {"end": 154.56, "start": 154.4, "text": "a"}, {"end": 155.2, "start": 154.56, "text": "surge"}, {"end": 155.48, "start": 155.2, "text": "in"}, {"end": 155.6, "start": 155.48, "text": "the"}, {"end": 156.24, "start": 155.6, "text": "development"}, {"end": 156.4, "start": 156.24, "text": "of"}, {"end": 156.72, "start": 156.4, "text": "time"}, {"end": 157.04, "start": 156.72, "text": "series"}, {"end": 157.52, "start": 157.04, "text": "foundation"}, {"end": 158.48, "start": 157.52, "text": "models."}, {"end": 158.64, "start": 158.48, "text": "For"}, {"end": 159.4, "start": 158.64, "text": "example,"}, {"end": 159.64, "start": 159.4, "text": "as"}, {"end": 160.2, "start": 159.64, "text": "shown"}, {"end": 160.36, "start": 160.2, "text": "in"}, {"end": 160.36, "start": 160.36, "text": "this"}, {"end": 160.48, "start": 160.36, "text": "table,"}, {"end": 160.84, "start": 160.48, "text": "some"}, {"end": 160.92, "start": 160.84, "text": "of"}, {"end": 161.16, "start": 160.92, "text": "these"}, {"end": 161.72, "start": 161.16, "text": "models,"}, {"end": 162.08, "start": 161.72, "text": "such"}, {"end": 162.36, "start": 162.08, "text": "as"}, {"end": 163.6, "start": 162.36, "text": "TimeLM,"}, {"end": 164.08, "start": 163.6, "text": "actually"}, {"end": 164.36, "start": 164.08, "text": "try"}, {"end": 164.56, "start": 164.36, "text": "to"}, {"end": 165.28, "start": 164.56, "text": "fine-tune"}, {"end": 165.72, "start": 165.28, "text": "language"}, {"end": 166.24, "start": 165.72, "text": "models"}, {"end": 166.4, "start": 166.24, "text": "for"}, {"end": 166.68, "start": 166.4, "text": "time"}, {"end": 167.04, "start": 166.68, "text": "series"}, {"end": 167.52, "start": 167.04, "text": "data"}, {"end": 168.0, "start": 167.52, "text": "based"}, {"end": 168.07999999999998, "start": 168.0, "text": "on"}, {"end": 168.64, "start": 168.07999999999998, "text": "adapters."}, {"end": 169.2, "start": 168.64, "text": "And"}, {"end": 169.48, "start": 169.2, "text": "other"}, {"end": 170.32, "start": 169.48, "text": "models,"}, {"end": 170.68, "start": 170.32, "text": "such"}, {"end": 170.92000000000002, "start": 170.68, "text": "as"}, {"end": 171.32, "start": 170.92000000000002, "text": "Croners"}, {"end": 172.16, "start": 171.32, "text": "and"}, {"end": 172.68, "start": 172.16, "text": "Moment"}, {"end": 172.84, "start": 172.68, "text": "model,"}, {"end": 173.2, "start": 172.84, "text": "they"}, {"end": 173.72, "start": 173.2, "text": "are"}, {"end": 173.92000000000002, "start": 173.72, "text": "trying"}, {"end": 173.96, "start": 173.92000000000002, "text": "to"}, {"end": 174.44, "start": 173.96, "text": "directly"}, {"end": 174.92000000000002, "start": 174.44, "text": "train"}, {"end": 175.64, "start": 174.92000000000002, "text": "transformers"}, {"end": 175.92000000000002, "start": 175.64, "text": "from"}, {"end": 176.64, "start": 175.92000000000002, "text": "scratch"}, {"end": 176.88, "start": 176.64, "text": "based"}, {"end": 177.0, "start": 176.88, "text": "on"}, {"end": 177.12, "start": 177.0, "text": "the"}, {"end": 177.4, "start": 177.12, "text": "time"}, {"end": 177.96, "start": 177.4, "text": "series"}, {"end": 179.96, "start": 177.96, "text": "data."}], "text": " So basically, just in the past years, we have seen a surge in the development of time series foundation models. For example, as shown in this table, some of these models, such as TimeLM, actually try to fine-tune language models for time series data based on adapters. And other models, such as Croners and Moment model, they are trying to directly train transformers from scratch based on the time series data."}, {"chunks": [{"end": 180.84, "start": 180.0, "text": "However,"}, {"end": 181.12, "start": 180.84, "text": "we"}, {"end": 181.4, "start": 181.12, "text": "recognize"}, {"end": 181.48, "start": 181.4, "text": "that"}, {"end": 181.76, "start": 181.48, "text": "just"}, {"end": 182.12, "start": 181.76, "text": "mentioned"}, {"end": 182.32, "start": 182.12, "text": "by"}, {"end": 182.92, "start": 182.32, "text": "Mary"}, {"end": 183.16, "start": 182.92, "text": "this"}, {"end": 183.52, "start": 183.16, "text": "morning,"}, {"end": 183.64, "start": 183.52, "text": "we"}, {"end": 183.92, "start": 183.64, "text": "found"}, {"end": 184.4, "start": 183.92, "text": "that"}, {"end": 184.52, "start": 184.4, "text": "many"}, {"end": 184.8, "start": 184.52, "text": "of"}, {"end": 185.08, "start": 184.8, "text": "these"}, {"end": 186.04, "start": 185.08, "text": "models"}, {"end": 186.24, "start": 186.04, "text": "do"}, {"end": 186.76, "start": 186.24, "text": "not"}, {"end": 187.16, "start": 186.76, "text": "fully"}, {"end": 187.44, "start": 187.16, "text": "meet"}, {"end": 187.96, "start": 187.44, "text": "the"}, {"end": 188.64, "start": 187.96, "text": "criterion"}, {"end": 188.8, "start": 188.64, "text": "to"}, {"end": 188.88, "start": 188.8, "text": "be"}, {"end": 189.44, "start": 188.88, "text": "considered"}, {"end": 189.72, "start": 189.44, "text": "as"}, {"end": 189.76, "start": 189.72, "text": "a"}, {"end": 190.32, "start": 189.76, "text": "true"}, {"end": 190.64, "start": 190.32, "text": "time"}, {"end": 190.92, "start": 190.64, "text": "series"}, {"end": 191.32, "start": 190.92, "text": "foundation"}, {"end": 192.68, "start": 191.32, "text": "model."}, {"end": 193.04, "start": 192.68, "text": "For"}, {"end": 193.92, "start": 193.04, "text": "example,"}, {"end": 194.32, "start": 193.92, "text": "some"}, {"end": 194.32, "start": 194.32, "text": "of"}, {"end": 194.64, "start": 194.32, "text": "these"}, {"end": 195.12, "start": 194.64, "text": "models"}, {"end": 195.36, "start": 195.12, "text": "does"}, {"end": 195.72, "start": 195.36, "text": "not"}, {"end": 196.2, "start": 195.72, "text": "account"}, {"end": 196.48, "start": 196.2, "text": "the"}, {"end": 196.8, "start": 196.48, "text": "time"}, {"end": 197.16, "start": 196.8, "text": "series"}, {"end": 198.4, "start": 197.16, "text": "characteristics"}, {"end": 198.92000000000002, "start": 198.4, "text": "because"}, {"end": 198.96, "start": 198.92000000000002, "text": "they"}, {"end": 199.4, "start": 198.96, "text": "just"}, {"end": 199.72, "start": 199.4, "text": "treat"}, {"end": 199.92000000000002, "start": 199.72, "text": "the"}, {"end": 200.4, "start": 199.92000000000002, "text": "data"}, {"end": 200.6, "start": 200.4, "text": "at"}, {"end": 201.04, "start": 200.6, "text": "simple"}, {"end": 201.88, "start": 201.04, "text": "sequences"}, {"end": 202.44, "start": 201.88, "text": "without"}, {"end": 203.07999999999998, "start": 202.44, "text": "incorporating"}, {"end": 203.28, "start": 203.07999999999998, "text": "the"}, {"end": 203.92000000000002, "start": 203.28, "text": "timestamp"}, {"end": 205.6, "start": 203.92000000000002, "text": "information."}, {"end": 206.04, "start": 205.6, "text": "And"}, {"end": 207.0, "start": 206.04, "text": "other"}, {"end": 207.68, "start": 207.0, "text": "models"}, {"end": 208.07999999999998, "start": 207.68, "text": "lack"}, {"end": 208.56, "start": 208.07999999999998, "text": "the"}, {"end": 209.28, "start": 208.56, "text": "foundational"}, {"end": 209.96, "start": 209.28, "text": "model"}], "text": " However, we recognize that just mentioned by Mary this morning, we found that many of these models do not fully meet the criterion to be considered as a true time series foundation model. For example, some of these models does not account the time series characteristics because they just treat the data at simple sequences without incorporating the timestamp information. And other models lack the foundational model"}, {"chunks": [{"end": 210.28, "start": 210.0, "text": "as"}, {"end": 210.64, "start": 210.28, "text": "best"}, {"end": 210.92, "start": 210.64, "text": "because"}, {"end": 211.12, "start": 210.92, "text": "they"}, {"end": 211.72, "start": 211.12, "text": "are"}, {"end": 212.12, "start": 211.72, "text": "not"}, {"end": 212.88, "start": 212.12, "text": "task"}, {"end": 213.52, "start": 212.88, "text": "agnostic."}, {"end": 214.24, "start": 213.52, "text": "Actually,"}, {"end": 214.72, "start": 214.24, "text": "most"}, {"end": 215.16, "start": 214.72, "text": "of"}, {"end": 215.48, "start": 215.16, "text": "these"}, {"end": 216.12, "start": 215.48, "text": "models"}, {"end": 216.24, "start": 216.12, "text": "are"}, {"end": 216.76, "start": 216.24, "text": "focused"}, {"end": 216.92, "start": 216.76, "text": "on"}, {"end": 217.52, "start": 216.92, "text": "forecasting"}, {"end": 220.88, "start": 217.52, "text": "tasks."}, {"end": 221.16, "start": 220.88, "text": "And"}, {"end": 221.96, "start": 221.16, "text": "furthermore,"}, {"end": 222.12, "start": 221.96, "text": "given"}, {"end": 222.56, "start": 222.12, "text": "the"}, {"end": 223.32, "start": 222.56, "text": "limitation"}, {"end": 223.6, "start": 223.32, "text": "that"}, {"end": 223.96, "start": 223.6, "text": "these"}, {"end": 224.36, "start": 223.96, "text": "foundation"}, {"end": 224.84, "start": 224.36, "text": "models"}, {"end": 225.6, "start": 224.84, "text": "cannot,"}, {"end": 226.16, "start": 225.6, "text": "most"}, {"end": 226.24, "start": 226.16, "text": "of"}, {"end": 226.48, "start": 226.24, "text": "these"}, {"end": 226.92000000000002, "start": 226.48, "text": "foundation"}, {"end": 227.28, "start": 226.92000000000002, "text": "models"}, {"end": 227.64, "start": 227.28, "text": "cannot"}, {"end": 228.12, "start": 227.64, "text": "handle"}, {"end": 228.92000000000002, "start": 228.12, "text": "covariance,"}, {"end": 229.6, "start": 228.92000000000002, "text": "so"}, {"end": 229.72, "start": 229.6, "text": "in"}, {"end": 229.92000000000002, "start": 229.72, "text": "this"}, {"end": 230.32, "start": 229.92000000000002, "text": "paper,"}, {"end": 230.56, "start": 230.32, "text": "we"}, {"end": 230.68, "start": 230.56, "text": "are"}, {"end": 231.04, "start": 230.68, "text": "mainly"}, {"end": 231.68, "start": 231.04, "text": "focused"}, {"end": 232.04, "start": 231.68, "text": "on"}, {"end": 232.92000000000002, "start": 232.04, "text": "univariate"}, {"end": 233.56, "start": 232.92000000000002, "text": "zero-shot"}, {"end": 234.16, "start": 233.56, "text": "forecasting"}, {"end": 234.68, "start": 234.16, "text": "tasks"}, {"end": 234.88, "start": 234.68, "text": "of"}, {"end": 235.12, "start": 234.88, "text": "these"}, {"end": 235.72, "start": 235.12, "text": "models"}, {"end": 235.88, "start": 235.72, "text": "in"}, {"end": 236.07999999999998, "start": 235.88, "text": "the"}, {"end": 236.68, "start": 236.07999999999998, "text": "context"}, {"end": 236.8, "start": 236.68, "text": "of"}, {"end": 237.12, "start": 236.8, "text": "building"}, {"end": 239.96, "start": 237.12, "text": "data."}], "text": " as best because they are not task agnostic. Actually, most of these models are focused on forecasting tasks. And furthermore, given the limitation that these foundation models cannot, most of these foundation models cannot handle covariance, so in this paper, we are mainly focused on univariate zero-shot forecasting tasks of these models in the context of building data."}, {"chunks": [{"end": 240.0, "start": 240.0, "text": "So"}, {"end": 240.44, "start": 240.0, "text": "to"}, {"end": 240.76, "start": 240.44, "text": "be"}, {"end": 241.4, "start": 240.76, "text": "more"}, {"end": 242.2, "start": 241.4, "text": "specifically,"}, {"end": 242.24, "start": 242.2, "text": "in"}, {"end": 242.56, "start": 242.24, "text": "this"}, {"end": 242.8, "start": 242.56, "text": "paper"}, {"end": 243.2, "start": 242.8, "text": "we"}, {"end": 243.64, "start": 243.2, "text": "are"}, {"end": 244.32, "start": 243.64, "text": "actually"}, {"end": 244.36, "start": 244.32, "text": "aimed"}, {"end": 244.68, "start": 244.36, "text": "to"}, {"end": 245.12, "start": 244.68, "text": "evaluate"}, {"end": 245.4, "start": 245.12, "text": "the"}, {"end": 246.12, "start": 245.4, "text": "generalizable"}, {"end": 246.72, "start": 246.12, "text": "ability"}, {"end": 246.96, "start": 246.72, "text": "of"}, {"end": 247.2, "start": 246.96, "text": "these"}, {"end": 247.88, "start": 247.2, "text": "current"}, {"end": 248.24, "start": 247.88, "text": "time"}, {"end": 248.48, "start": 248.24, "text": "series"}, {"end": 248.96, "start": 248.48, "text": "foundation"}, {"end": 249.56, "start": 248.96, "text": "models"}, {"end": 249.72, "start": 249.56, "text": "in"}, {"end": 250.28, "start": 249.72, "text": "two"}, {"end": 251.4, "start": 250.28, "text": "aspects."}, {"end": 251.76, "start": 251.4, "text": "So"}, {"end": 252.2, "start": 251.76, "text": "including"}, {"end": 252.56, "start": 252.2, "text": "the"}, {"end": 253.04, "start": 252.56, "text": "dataset"}, {"end": 253.36, "start": 253.04, "text": "level"}, {"end": 254.16, "start": 253.36, "text": "familiarity,"}, {"end": 254.4, "start": 254.16, "text": "which"}, {"end": 254.92, "start": 254.4, "text": "means"}, {"end": 255.12, "start": 254.92, "text": "whether"}, {"end": 256.0, "start": 255.12, "text": "this"}, {"end": 256.56, "start": 256.0, "text": "model"}, {"end": 257.08, "start": 256.56, "text": "has"}, {"end": 257.28, "start": 257.08, "text": "been"}, {"end": 257.92, "start": 257.28, "text": "exposed"}, {"end": 258.2, "start": 257.92, "text": "to"}, {"end": 258.48, "start": 258.2, "text": "the"}, {"end": 258.88, "start": 258.48, "text": "test"}, {"end": 259.36, "start": 258.88, "text": "data"}, {"end": 259.52, "start": 259.36, "text": "in"}, {"end": 260.24, "start": 259.52, "text": "model"}, {"end": 261.36, "start": 260.24, "text": "training,"}, {"end": 261.52, "start": 261.36, "text": "as"}, {"end": 262.08, "start": 261.52, "text": "well"}, {"end": 262.2, "start": 262.08, "text": "as"}, {"end": 262.2, "start": 262.2, "text": "the"}, {"end": 262.8, "start": 262.2, "text": "modality"}, {"end": 263.04, "start": 262.8, "text": "level"}, {"end": 263.76, "start": 263.04, "text": "familiarity,"}, {"end": 264.04, "start": 263.76, "text": "which"}, {"end": 264.6, "start": 264.04, "text": "means"}, {"end": 264.92, "start": 264.6, "text": "whether"}, {"end": 265.16, "start": 264.92, "text": "this"}, {"end": 265.44, "start": 265.16, "text": "model"}, {"end": 265.76, "start": 265.44, "text": "has"}, {"end": 265.96, "start": 265.76, "text": "been"}, {"end": 266.44, "start": 265.96, "text": "trained"}, {"end": 266.6, "start": 266.44, "text": "with"}, {"end": 266.88, "start": 266.6, "text": "the"}, {"end": 267.36, "start": 266.88, "text": "same"}, {"end": 267.76, "start": 267.36, "text": "data"}, {"end": 268.48, "start": 267.76, "text": "modality"}, {"end": 268.68, "start": 268.48, "text": "as"}, {"end": 269.12, "start": 268.68, "text": "test"}, {"end": 269.96, "start": 269.12, "text": "set."}], "text": " So to be more specifically, in this paper we are actually aimed to evaluate the generalizable ability of these current time series foundation models in two aspects. So including the dataset level familiarity, which means whether this model has been exposed to the test data in model training, as well as the modality level familiarity, which means whether this model has been trained with the same data modality as test set."}, {"chunks": [{"end": 270.2, "start": 270.0, "text": "So"}, {"end": 270.6, "start": 270.2, "text": "for"}, {"end": 271.08, "start": 270.6, "text": "example,"}, {"end": 271.12, "start": 271.08, "text": "in"}, {"end": 271.36, "start": 271.12, "text": "this"}, {"end": 271.8, "start": 271.36, "text": "work"}, {"end": 271.92, "start": 271.8, "text": "we"}, {"end": 272.8, "start": 271.92, "text": "consider"}, {"end": 273.0, "start": 272.8, "text": "indoor"}, {"end": 273.88, "start": 273.0, "text": "temperature"}, {"end": 274.08, "start": 273.88, "text": "and"}, {"end": 274.64, "start": 274.08, "text": "energy"}, {"end": 275.16, "start": 274.64, "text": "consumption"}, {"end": 275.4, "start": 275.16, "text": "as"}, {"end": 275.8, "start": 275.4, "text": "different"}, {"end": 277.96, "start": 275.8, "text": "modalities."}, {"end": 278.88, "start": 277.96, "text": "And"}, {"end": 279.44, "start": 278.88, "text": "we"}, {"end": 279.96, "start": 279.44, "text": "also"}, {"end": 280.88, "start": 279.96, "text": "evaluate"}, {"end": 281.48, "start": 280.88, "text": "the"}, {"end": 282.2, "start": 281.48, "text": "performance"}, {"end": 282.72, "start": 282.2, "text": "on"}, {"end": 283.08, "start": 282.72, "text": "three"}, {"end": 283.56, "start": 283.08, "text": "large"}, {"end": 283.96, "start": 283.56, "text": "public"}, {"end": 284.92, "start": 283.96, "text": "datasets"}, {"end": 285.48, "start": 284.92, "text": "including"}, {"end": 285.96, "start": 285.48, "text": "the"}, {"end": 286.52, "start": 285.96, "text": "ECOPI"}, {"end": 286.96, "start": 286.52, "text": "datasets"}, {"end": 287.48, "start": 286.96, "text": "that"}, {"end": 288.08, "start": 287.48, "text": "aims"}, {"end": 288.56, "start": 288.08, "text": "for"}, {"end": 288.8, "start": 288.56, "text": "indoor"}, {"end": 290.08, "start": 288.8, "text": "temperature"}, {"end": 290.72, "start": 290.08, "text": "prediction"}, {"end": 291.2, "start": 290.72, "text": "as"}, {"end": 291.32, "start": 291.2, "text": "well"}, {"end": 291.8, "start": 291.32, "text": "as"}, {"end": 291.84, "start": 291.8, "text": "the"}, {"end": 292.44, "start": 291.84, "text": "UCI"}, {"end": 292.88, "start": 292.44, "text": "and"}, {"end": 294.0, "start": 292.88, "text": "SmartStar"}, {"end": 294.96, "start": 294.0, "text": "datasets"}, {"end": 295.48, "start": 294.96, "text": "that"}, {"end": 296.32, "start": 295.48, "text": "focus"}, {"end": 296.52, "start": 296.32, "text": "on"}, {"end": 296.64, "start": 296.52, "text": "the"}, {"end": 297.04, "start": 296.64, "text": "energy"}, {"end": 297.64, "start": 297.04, "text": "consumption"}, {"end": 299.96, "start": 297.64, "text": "predictions."}], "text": " So for example, in this work we consider indoor temperature and energy consumption as different modalities. And we also evaluate the performance on three large public datasets including the ECOPI datasets that aims for indoor temperature prediction as well as the UCI and SmartStar datasets that focus on the energy consumption predictions."}, {"chunks": [{"end": 301.28, "start": 300.0, "text": "However,"}, {"end": 301.76, "start": 301.28, "text": "before"}, {"end": 302.2, "start": 301.76, "text": "our"}, {"end": 303.36, "start": 302.2, "text": "evaluations,"}, {"end": 303.68, "start": 303.36, "text": "we"}, {"end": 304.16, "start": 303.68, "text": "noticed"}, {"end": 304.52, "start": 304.16, "text": "that"}, {"end": 304.68, "start": 304.52, "text": "the"}, {"end": 305.04, "start": 304.68, "text": "time"}, {"end": 305.32, "start": 305.04, "text": "series"}, {"end": 305.84, "start": 305.32, "text": "data"}, {"end": 306.08, "start": 305.84, "text": "in"}, {"end": 306.6, "start": 306.08, "text": "building"}, {"end": 307.12, "start": 306.6, "text": "analytics"}, {"end": 307.44, "start": 307.12, "text": "is"}, {"end": 307.96, "start": 307.44, "text": "often"}, {"end": 308.68, "start": 307.96, "text": "highly"}, {"end": 309.36, "start": 308.68, "text": "heterogeneous"}, {"end": 309.6, "start": 309.36, "text": "and"}, {"end": 310.24, "start": 309.6, "text": "contextual"}, {"end": 311.64, "start": 310.24, "text": "varied."}, {"end": 311.72, "start": 311.64, "text": "For"}, {"end": 312.84, "start": 311.72, "text": "example,"}, {"end": 312.92, "start": 312.84, "text": "in"}, {"end": 313.28, "start": 312.92, "text": "some"}, {"end": 313.96, "start": 313.28, "text": "scenarios,"}, {"end": 314.28, "start": 313.96, "text": "we"}, {"end": 314.8, "start": 314.28, "text": "may"}, {"end": 315.48, "start": 314.8, "text": "only"}, {"end": 316.12, "start": 315.48, "text": "require"}, {"end": 316.28, "start": 316.12, "text": "to"}, {"end": 316.52, "start": 316.28, "text": "predict"}, {"end": 317.04, "start": 316.52, "text": "data"}, {"end": 317.28, "start": 317.04, "text": "in"}, {"end": 317.36, "start": 317.28, "text": "the"}, {"end": 317.64, "start": 317.36, "text": "next"}, {"end": 317.92, "start": 317.64, "text": "four"}, {"end": 319.52, "start": 317.92, "text": "hours,"}, {"end": 319.88, "start": 319.52, "text": "but"}, {"end": 319.92, "start": 319.88, "text": "in"}, {"end": 320.2, "start": 319.92, "text": "other"}, {"end": 320.8, "start": 320.2, "text": "cases,"}, {"end": 321.12, "start": 320.8, "text": "we"}, {"end": 321.68, "start": 321.12, "text": "might"}, {"end": 321.84, "start": 321.68, "text": "need"}, {"end": 321.92, "start": 321.84, "text": "to"}, {"end": 322.04, "start": 321.92, "text": "make"}, {"end": 322.84, "start": 322.04, "text": "predictions"}, {"end": 322.88, "start": 322.84, "text": "in"}, {"end": 323.24, "start": 322.88, "text": "12"}, {"end": 323.84, "start": 323.24, "text": "hours"}, {"end": 324.28, "start": 323.84, "text": "or"}, {"end": 324.96, "start": 324.28, "text": "even"}, {"end": 325.44, "start": 324.96, "text": "longer."}, {"end": 326.36, "start": 325.44, "text": "However,"}, {"end": 326.76, "start": 326.36, "text": "we"}, {"end": 327.68, "start": 326.76, "text": "find"}, {"end": 328.2, "start": 327.68, "text": "that"}, {"end": 328.52, "start": 328.2, "text": "most"}, {"end": 328.6, "start": 328.52, "text": "of"}, {"end": 328.64, "start": 328.6, "text": "current"}, {"end": 329.0, "start": 328.64, "text": "time"}, {"end": 329.36, "start": 329.0, "text": "series"}, {"end": 329.96, "start": 329.36, "text": "foundations"}], "text": " However, before our evaluations, we noticed that the time series data in building analytics is often highly heterogeneous and contextual varied. For example, in some scenarios, we may only require to predict data in the next four hours, but in other cases, we might need to make predictions in 12 hours or even longer. However, we find that most of current time series foundations"}, {"chunks": [{"end": 330.84, "start": 330.0, "text": "models"}, {"end": 331.12, "start": 330.84, "text": "are"}, {"end": 331.64, "start": 331.12, "text": "optimized"}, {"end": 331.84, "start": 331.64, "text": "to"}, {"end": 332.16, "start": 331.84, "text": "make"}, {"end": 333.04, "start": 332.16, "text": "predictions"}, {"end": 333.16, "start": 333.04, "text": "in"}, {"end": 333.44, "start": 333.16, "text": "a"}, {"end": 334.48, "start": 333.44, "text": "specific"}, {"end": 334.76, "start": 334.48, "text": "limit"}, {"end": 335.24, "start": 334.76, "text": "of"}, {"end": 335.84, "start": 335.24, "text": "input"}, {"end": 336.08, "start": 335.84, "text": "and"}, {"end": 336.96, "start": 336.08, "text": "output"}, {"end": 337.6, "start": 336.96, "text": "length."}, {"end": 338.16, "start": 337.6, "text": "So"}, {"end": 338.56, "start": 338.16, "text": "in"}, {"end": 338.56, "start": 338.56, "text": "order"}, {"end": 338.56, "start": 338.56, "text": "to"}, {"end": 339.08, "start": 338.56, "text": "incorporate"}, {"end": 339.28, "start": 339.08, "text": "the"}, {"end": 340.12, "start": 339.28, "text": "variability"}, {"end": 340.24, "start": 340.12, "text": "of"}, {"end": 340.6, "start": 340.24, "text": "different"}, {"end": 340.84, "start": 340.6, "text": "time"}, {"end": 341.08, "start": 340.84, "text": "series"}, {"end": 341.48, "start": 341.08, "text": "data,"}, {"end": 341.72, "start": 341.48, "text": "we"}, {"end": 342.4, "start": 341.72, "text": "actually"}, {"end": 342.84, "start": 342.4, "text": "resample"}, {"end": 343.16, "start": 342.84, "text": "the"}, {"end": 343.48, "start": 343.16, "text": "time"}, {"end": 343.84, "start": 343.48, "text": "series"}, {"end": 344.52, "start": 343.84, "text": "data"}, {"end": 344.96, "start": 344.52, "text": "and"}, {"end": 345.6, "start": 344.96, "text": "evaluate"}, {"end": 345.72, "start": 345.6, "text": "the"}, {"end": 346.04, "start": 345.72, "text": "model"}, {"end": 346.64, "start": 346.04, "text": "performance"}, {"end": 346.96, "start": 346.64, "text": "in"}, {"end": 347.2, "start": 346.96, "text": "the"}, {"end": 347.56, "start": 347.2, "text": "three"}, {"end": 348.28, "start": 347.56, "text": "key"}, {"end": 349.16, "start": 348.28, "text": "factors,"}, {"end": 349.76, "start": 349.16, "text": "including"}, {"end": 350.24, "start": 349.76, "text": "different"}, {"end": 350.92, "start": 350.24, "text": "context"}, {"end": 351.16, "start": 350.92, "text": "window"}, {"end": 351.48, "start": 351.16, "text": "of"}, {"end": 351.8, "start": 351.48, "text": "input"}, {"end": 352.52, "start": 351.8, "text": "data,"}, {"end": 352.88, "start": 352.52, "text": "different"}, {"end": 353.6, "start": 352.88, "text": "horizons"}, {"end": 354.04, "start": 353.6, "text": "of"}, {"end": 354.6, "start": 354.04, "text": "output"}, {"end": 355.32, "start": 354.6, "text": "data,"}, {"end": 355.92, "start": 355.32, "text": "as"}, {"end": 356.28, "start": 355.92, "text": "well"}, {"end": 356.48, "start": 356.28, "text": "as"}, {"end": 358.92, "start": 356.48, "text": "different"}, {"end": 359.48, "start": 358.92, "text": "sampling"}, {"end": 359.96, "start": 359.48, "text": "rates."}], "text": " models are optimized to make predictions in a specific limit of input and output length. So in order to incorporate the variability of different time series data, we actually resample the time series data and evaluate the model performance in the three key factors, including different context window of input data, different horizons of output data, as well as different sampling rates."}, {"chunks": [{"end": 360.64, "start": 360.0, "text": "also"}, {"end": 360.84, "start": 360.64, "text": "compare"}, {"end": 361.0, "start": 360.84, "text": "the"}, {"end": 361.68, "start": 361.0, "text": "performance"}, {"end": 362.08, "start": 361.68, "text": "with"}, {"end": 362.84, "start": 362.08, "text": "statistical"}, {"end": 363.16, "start": 362.84, "text": "Arrhythma"}, {"end": 363.68, "start": 363.16, "text": "models"}, {"end": 364.04, "start": 363.68, "text": "and"}, {"end": 364.56, "start": 364.04, "text": "these"}, {"end": 365.08, "start": 364.56, "text": "statistic"}, {"end": 365.64, "start": 365.08, "text": "models"}, {"end": 365.76, "start": 365.64, "text": "were"}, {"end": 366.16, "start": 365.76, "text": "trained"}, {"end": 366.48, "start": 366.16, "text": "from"}, {"end": 367.24, "start": 366.48, "text": "scratch"}, {"end": 367.72, "start": 367.24, "text": "only"}, {"end": 367.76, "start": 367.72, "text": "on"}, {"end": 368.04, "start": 367.76, "text": "our"}, {"end": 368.68, "start": 368.04, "text": "specific"}, {"end": 369.2, "start": 368.68, "text": "context"}, {"end": 369.44, "start": 369.2, "text": "window."}, {"end": 370.24, "start": 369.44, "text": "And"}, {"end": 370.8, "start": 370.24, "text": "similarly,"}, {"end": 371.24, "start": 370.8, "text": "they"}, {"end": 372.0, "start": 371.24, "text": "were"}, {"end": 372.6, "start": 372.0, "text": "also"}, {"end": 372.84, "start": 372.6, "text": "used"}, {"end": 373.48, "start": 372.84, "text": "to"}, {"end": 374.56, "start": 373.48, "text": "make"}, {"end": 375.12, "start": 374.56, "text": "prediction"}, {"end": 375.36, "start": 375.12, "text": "on"}, {"end": 375.76, "start": 375.36, "text": "both"}, {"end": 376.48, "start": 375.76, "text": "shorter"}, {"end": 376.68, "start": 376.48, "text": "and"}, {"end": 377.12, "start": 376.68, "text": "longer"}, {"end": 380.44, "start": 377.12, "text": "durations."}, {"end": 380.96, "start": 380.44, "text": "So"}, {"end": 380.96, "start": 380.96, "text": "in"}, {"end": 381.48, "start": 380.96, "text": "the"}, {"end": 382.52, "start": 381.48, "text": "evaluations,"}, {"end": 382.8, "start": 382.52, "text": "we"}, {"end": 383.16, "start": 382.8, "text": "first"}, {"end": 383.8, "start": 383.16, "text": "evaluate"}, {"end": 384.12, "start": 383.8, "text": "the"}, {"end": 384.72, "start": 384.12, "text": "prediction"}, {"end": 385.32, "start": 384.72, "text": "arrows"}, {"end": 385.4, "start": 385.32, "text": "of"}, {"end": 385.76, "start": 385.4, "text": "different"}, {"end": 386.48, "start": 385.76, "text": "models"}, {"end": 386.48, "start": 386.48, "text": "on"}, {"end": 386.92, "start": 386.48, "text": "the"}, {"end": 387.2, "start": 386.92, "text": "UCI"}, {"end": 387.76, "start": 387.2, "text": "dataset"}, {"end": 387.76, "start": 387.76, "text": "and"}, {"end": 388.12, "start": 387.76, "text": "we"}, {"end": 388.68, "start": 388.12, "text": "call"}, {"end": 388.92, "start": 388.68, "text": "this"}, {"end": 389.44, "start": 388.92, "text": "dataset"}, {"end": 389.96, "start": 389.44, "text": "as"}], "text": " also compare the performance with statistical Arrhythma models and these statistic models were trained from scratch only on our specific context window. And similarly, they were also used to make prediction on both shorter and longer durations. So in the evaluations, we first evaluate the prediction arrows of different models on the UCI dataset and we call this dataset as"}, {"chunks": [{"end": 390.68, "start": 390.0, "text": "as"}, {"end": 390.96, "start": 390.68, "text": "seen"}, {"end": 391.68, "start": 390.96, "text": "dataset"}, {"end": 392.16, "start": 391.68, "text": "because"}, {"end": 392.56, "start": 392.16, "text": "there"}, {"end": 392.64, "start": 392.56, "text": "are"}, {"end": 393.0, "start": 392.64, "text": "four"}, {"end": 393.24, "start": 393.0, "text": "time"}, {"end": 393.48, "start": 393.24, "text": "series"}, {"end": 393.96, "start": 393.48, "text": "foundation"}, {"end": 394.52, "start": 393.96, "text": "models"}, {"end": 394.72, "start": 394.52, "text": "being"}, {"end": 395.04, "start": 394.72, "text": "trained"}, {"end": 395.36, "start": 395.04, "text": "using"}, {"end": 395.56, "start": 395.36, "text": "this"}, {"end": 396.04, "start": 395.56, "text": "data,"}, {"end": 396.8, "start": 396.04, "text": "including"}, {"end": 397.32, "start": 396.8, "text": "the"}, {"end": 398.08, "start": 397.32, "text": "moment,"}, {"end": 398.8, "start": 398.08, "text": "corners,"}, {"end": 399.32, "start": 398.8, "text": "lag-lama,"}, {"end": 399.68, "start": 399.32, "text": "and"}, {"end": 400.16, "start": 399.68, "text": "times"}, {"end": 400.44, "start": 400.16, "text": "FM"}, {"end": 401.0, "start": 400.44, "text": "model."}, {"end": 401.48, "start": 401.0, "text": "And"}, {"end": 401.56, "start": 401.48, "text": "here"}, {"end": 401.96, "start": 401.56, "text": "we"}, {"end": 402.16, "start": 401.96, "text": "use"}, {"end": 402.4, "start": 402.16, "text": "the"}, {"end": 402.72, "start": 402.4, "text": "red"}, {"end": 403.68, "start": 402.72, "text": "horizontal"}, {"end": 404.08, "start": 403.68, "text": "line"}, {"end": 404.28, "start": 404.08, "text": "to"}, {"end": 404.64, "start": 404.28, "text": "show"}, {"end": 404.84, "start": 404.64, "text": "the"}, {"end": 405.16, "start": 404.84, "text": "best"}, {"end": 405.88, "start": 405.16, "text": "performance"}, {"end": 406.32, "start": 405.88, "text": "of"}, {"end": 407.0, "start": 406.32, "text": "statistical"}, {"end": 407.44, "start": 407.0, "text": "model"}, {"end": 407.68, "start": 407.44, "text": "and"}, {"end": 407.96, "start": 407.68, "text": "use"}, {"end": 408.32, "start": 407.96, "text": "the"}, {"end": 408.48, "start": 408.32, "text": "blue"}, {"end": 408.8, "start": 408.48, "text": "line"}, {"end": 408.96, "start": 408.8, "text": "to"}, {"end": 409.16, "start": 408.96, "text": "show"}, {"end": 409.52, "start": 409.16, "text": "the"}, {"end": 410.12, "start": 409.52, "text": "best"}, {"end": 411.04, "start": 410.12, "text": "performance"}, {"end": 411.28, "start": 411.04, "text": "of"}, {"end": 411.48, "start": 411.28, "text": "time"}, {"end": 411.8, "start": 411.48, "text": "series"}, {"end": 412.28, "start": 411.8, "text": "foundation"}, {"end": 412.48, "start": 412.28, "text": "model."}, {"end": 413.0, "start": 412.48, "text": "And"}, {"end": 413.56, "start": 413.0, "text": "lower"}, {"end": 414.08, "start": 413.56, "text": "is"}, {"end": 414.48, "start": 414.08, "text": "better"}, {"end": 415.12, "start": 414.48, "text": "because"}, {"end": 415.64, "start": 415.12, "text": "we"}, {"end": 415.96, "start": 415.64, "text": "are"}, {"end": 416.08, "start": 415.96, "text": "evaluating"}, {"end": 416.08, "start": 416.08, "text": "the"}, {"end": 416.56, "start": 416.08, "text": "prediction"}, {"end": 417.0, "start": 416.56, "text": "errors."}, {"end": 417.16, "start": 417.0, "text": "And"}, {"end": 417.28, "start": 417.16, "text": "as"}, {"end": 417.6, "start": 417.28, "text": "you"}, {"end": 418.08, "start": 417.6, "text": "can"}, {"end": 418.68, "start": 418.08, "text": "see,"}, {"end": 418.92, "start": 418.68, "text": "in"}, {"end": 419.4, "start": 418.92, "text": "this"}, {"end": 419.96, "start": 419.4, "text": "comparison,"}], "text": " as seen dataset because there are four time series foundation models being trained using this data, including the moment, corners, lag-lama, and times FM model. And here we use the red horizontal line to show the best performance of statistical model and use the blue line to show the best performance of time series foundation model. And lower is better because we are evaluating the prediction errors. And as you can see, in this comparison,"}, {"chunks": [{"end": 420.72, "start": 420.0, "text": "of"}, {"end": 421.04, "start": 420.72, "text": "seen"}, {"end": 421.72, "start": 421.04, "text": "datasets,"}, {"end": 422.24, "start": 421.72, "text": "time"}, {"end": 422.56, "start": 422.24, "text": "series"}, {"end": 423.08, "start": 422.56, "text": "foundation"}, {"end": 423.56, "start": 423.08, "text": "models"}, {"end": 424.28, "start": 423.56, "text": "actually"}, {"end": 424.6, "start": 424.28, "text": "show"}, {"end": 425.16, "start": 424.6, "text": "superior"}, {"end": 425.88, "start": 425.16, "text": "performance"}, {"end": 426.24, "start": 425.88, "text": "than"}, {"end": 426.92, "start": 426.24, "text": "statistical"}, {"end": 430.12, "start": 426.92, "text": "models."}, {"end": 430.48, "start": 430.12, "text": "And"}, {"end": 430.68, "start": 430.48, "text": "we"}, {"end": 431.08, "start": 430.68, "text": "also"}, {"end": 431.44, "start": 431.08, "text": "evaluate"}, {"end": 431.6, "start": 431.44, "text": "the"}, {"end": 432.24, "start": 431.6, "text": "performance"}, {"end": 432.72, "start": 432.24, "text": "on"}, {"end": 433.28, "start": 432.72, "text": "the"}, {"end": 433.92, "start": 433.28, "text": "SmartStar"}, {"end": 435.12, "start": 433.92, "text": "datasets,"}, {"end": 435.48, "start": 435.12, "text": "where"}, {"end": 435.92, "start": 435.48, "text": "none"}, {"end": 435.92, "start": 435.92, "text": "of"}, {"end": 436.28, "start": 435.92, "text": "these"}, {"end": 436.56, "start": 436.28, "text": "time"}, {"end": 436.76, "start": 436.56, "text": "series"}, {"end": 437.2, "start": 436.76, "text": "foundation"}, {"end": 437.56, "start": 437.2, "text": "models"}, {"end": 437.76, "start": 437.56, "text": "have"}, {"end": 438.04, "start": 437.76, "text": "seen"}, {"end": 438.32, "start": 438.04, "text": "this"}, {"end": 438.56, "start": 438.32, "text": "data"}, {"end": 439.76, "start": 438.56, "text": "before."}, {"end": 440.24, "start": 439.76, "text": "And"}, {"end": 440.72, "start": 440.24, "text": "as"}, {"end": 440.72, "start": 440.72, "text": "you"}, {"end": 440.92, "start": 440.72, "text": "can"}, {"end": 441.36, "start": 440.92, "text": "see,"}, {"end": 441.84, "start": 441.36, "text": "in"}, {"end": 442.4, "start": 441.84, "text": "these"}, {"end": 442.84, "start": 442.4, "text": "unseen"}, {"end": 443.4, "start": 442.84, "text": "datasets,"}, {"end": 443.56, "start": 443.4, "text": "the"}, {"end": 444.12, "start": 443.56, "text": "performance"}, {"end": 444.6, "start": 444.12, "text": "gap"}, {"end": 444.96, "start": 444.6, "text": "between"}, {"end": 445.16, "start": 444.96, "text": "the"}, {"end": 445.4, "start": 445.16, "text": "time"}, {"end": 445.8, "start": 445.4, "text": "series"}, {"end": 446.12, "start": 445.8, "text": "foundation"}, {"end": 446.6, "start": 446.12, "text": "models"}, {"end": 446.88, "start": 446.6, "text": "and"}, {"end": 447.6, "start": 446.88, "text": "statistical"}, {"end": 448.28, "start": 447.6, "text": "approaches"}, {"end": 448.96, "start": 448.28, "text": "narrows"}, {"end": 449.96, "start": 448.96, "text": "significantly."}], "text": " of seen datasets, time series foundation models actually show superior performance than statistical models. And we also evaluate the performance on the SmartStar datasets, where none of these time series foundation models have seen this data before. And as you can see, in these unseen datasets, the performance gap between the time series foundation models and statistical approaches narrows significantly."}, {"chunks": [{"end": 450.4, "start": 450.0, "text": "We"}, {"end": 450.76, "start": 450.4, "text": "show"}, {"end": 451.2, "start": 450.76, "text": "that"}, {"end": 451.48, "start": 451.2, "text": "on"}, {"end": 451.96, "start": 451.48, "text": "unseen"}, {"end": 452.6, "start": 451.96, "text": "data,"}, {"end": 453.56, "start": 452.6, "text": "TSFMs"}, {"end": 454.2, "start": 453.56, "text": "only"}, {"end": 454.56, "start": 454.2, "text": "have"}, {"end": 455.12, "start": 454.56, "text": "marginal"}, {"end": 455.72, "start": 455.12, "text": "performance"}, {"end": 460.08, "start": 455.72, "text": "improvement."}, {"end": 460.48, "start": 460.08, "text": "And"}, {"end": 460.8, "start": 460.48, "text": "we"}, {"end": 461.36, "start": 460.8, "text": "also"}, {"end": 461.8, "start": 461.36, "text": "compare"}, {"end": 461.88, "start": 461.8, "text": "the"}, {"end": 462.84, "start": 461.88, "text": "performance"}, {"end": 463.0, "start": 462.84, "text": "on"}, {"end": 463.52, "start": 463.0, "text": "unseen"}, {"end": 464.64, "start": 463.52, "text": "modalities."}, {"end": 464.96, "start": 464.64, "text": "So"}, {"end": 465.16, "start": 464.96, "text": "here"}, {"end": 465.36, "start": 465.16, "text": "we"}, {"end": 465.72, "start": 465.36, "text": "use"}, {"end": 466.2, "start": 465.72, "text": "the"}, {"end": 466.64, "start": 466.2, "text": "Ecobee"}, {"end": 467.68, "start": 466.64, "text": "datasets"}, {"end": 468.32, "start": 467.68, "text": "for"}, {"end": 468.6, "start": 468.32, "text": "indoor"}, {"end": 469.28, "start": 468.6, "text": "temperature"}, {"end": 469.68, "start": 469.28, "text": "prediction"}, {"end": 470.24, "start": 469.68, "text": "because"}, {"end": 470.76, "start": 470.24, "text": "we"}, {"end": 471.4, "start": 470.76, "text": "found"}, {"end": 472.28, "start": 471.4, "text": "that"}, {"end": 473.0, "start": 472.28, "text": "now"}, {"end": 473.56, "start": 473.0, "text": "these"}, {"end": 474.32, "start": 473.56, "text": "time"}, {"end": 475.76, "start": 474.32, "text": "series"}, {"end": 476.64, "start": 475.76, "text": "foundation"}, {"end": 477.04, "start": 476.64, "text": "models"}, {"end": 477.72, "start": 477.04, "text": "have"}, {"end": 477.92, "start": 477.72, "text": "been"}, {"end": 478.64, "start": 477.92, "text": "trained"}, {"end": 478.68, "start": 478.64, "text": "on"}, {"end": 479.16, "start": 478.68, "text": "indoor"}, {"end": 479.72, "start": 479.16, "text": "temperature"}, {"end": 479.96, "start": 479.72, "text": "data."}], "text": " We show that on unseen data, TSFMs only have marginal performance improvement. And we also compare the performance on unseen modalities. So here we use the Ecobee datasets for indoor temperature prediction because we found that now these time series foundation models have been trained on indoor temperature data."}, {"chunks": [{"end": 480.48, "start": 480.0, "text": "foundation"}, {"end": 481.16, "start": 480.48, "text": "models"}, {"end": 481.56, "start": 481.16, "text": "have"}, {"end": 481.92, "start": 481.56, "text": "not"}, {"end": 482.48, "start": 481.92, "text": "seen"}, {"end": 483.44, "start": 482.48, "text": "this"}, {"end": 484.16, "start": 483.44, "text": "data"}, {"end": 484.92, "start": 484.16, "text": "modality"}, {"end": 485.64, "start": 484.92, "text": "before,"}, {"end": 486.28, "start": 485.64, "text": "they"}, {"end": 486.56, "start": 486.28, "text": "do"}, {"end": 487.0, "start": 486.56, "text": "not"}, {"end": 487.56, "start": 487.0, "text": "perform"}, {"end": 487.88, "start": 487.56, "text": "much"}, {"end": 488.4, "start": 487.88, "text": "better"}, {"end": 488.64, "start": 488.4, "text": "than"}, {"end": 488.96, "start": 488.64, "text": "the"}, {"end": 489.68, "start": 488.96, "text": "statistical"}, {"end": 491.56, "start": 489.68, "text": "models."}, {"end": 492.24, "start": 491.56, "text": "So"}, {"end": 492.8, "start": 492.24, "text": "we"}, {"end": 493.6, "start": 492.8, "text": "can"}, {"end": 493.76, "start": 493.6, "text": "see"}, {"end": 494.4, "start": 493.76, "text": "that"}, {"end": 495.12, "start": 494.4, "text": "actually"}, {"end": 495.24, "start": 495.12, "text": "on"}, {"end": 495.8, "start": 495.24, "text": "unseen"}, {"end": 496.6, "start": 495.8, "text": "datasets"}, {"end": 497.04, "start": 496.6, "text": "or"}, {"end": 497.44, "start": 497.04, "text": "unseen"}, {"end": 498.48, "start": 497.44, "text": "modalities,"}, {"end": 499.04, "start": 498.48, "text": "the"}, {"end": 499.52, "start": 499.04, "text": "performance"}, {"end": 499.92, "start": 499.52, "text": "gap"}, {"end": 500.28, "start": 499.92, "text": "between"}, {"end": 500.64, "start": 500.28, "text": "time"}, {"end": 501.0, "start": 500.64, "text": "series"}, {"end": 501.44, "start": 501.0, "text": "foundation"}, {"end": 502.04, "start": 501.44, "text": "models"}, {"end": 502.36, "start": 502.04, "text": "and"}, {"end": 502.76, "start": 502.36, "text": "statistic"}, {"end": 503.2, "start": 502.76, "text": "models"}, {"end": 503.68, "start": 503.2, "text": "actually"}, {"end": 503.96, "start": 503.68, "text": "is"}, {"end": 504.36, "start": 503.96, "text": "very"}, {"end": 507.2, "start": 504.36, "text": "marginal."}, {"end": 507.88, "start": 507.2, "text": "So"}, {"end": 508.44, "start": 507.88, "text": "based"}, {"end": 508.68, "start": 508.44, "text": "on"}, {"end": 509.12, "start": 508.68, "text": "these"}, {"end": 509.96, "start": 509.12, "text": "evaluations,"}], "text": " foundation models have not seen this data modality before, they do not perform much better than the statistical models. So we can see that actually on unseen datasets or unseen modalities, the performance gap between time series foundation models and statistic models actually is very marginal. So based on these evaluations,"}, {"chunks": [{"end": 510.32, "start": 510.0, "text": "we"}, {"end": 511.16, "start": 510.32, "text": "found"}, {"end": 511.48, "start": 511.16, "text": "that"}, {"end": 512.2, "start": 511.48, "text": "currently"}, {"end": 512.6, "start": 512.2, "text": "these"}, {"end": 513.04, "start": 512.6, "text": "time"}, {"end": 513.24, "start": 513.04, "text": "series"}, {"end": 513.72, "start": 513.24, "text": "foundation"}, {"end": 514.32, "start": 513.72, "text": "models"}, {"end": 514.8, "start": 514.32, "text": "cannot"}, {"end": 515.16, "start": 514.8, "text": "fully"}, {"end": 515.48, "start": 515.16, "text": "meet"}, {"end": 515.72, "start": 515.48, "text": "our"}, {"end": 516.24, "start": 515.72, "text": "needs"}, {"end": 516.44, "start": 516.24, "text": "for"}, {"end": 516.84, "start": 516.44, "text": "building"}, {"end": 518.28, "start": 516.84, "text": "analytics."}, {"end": 518.6, "start": 518.28, "text": "So,"}, {"end": 519.0, "start": 518.6, "text": "and"}, {"end": 519.72, "start": 519.0, "text": "to"}, {"end": 519.88, "start": 519.72, "text": "further"}, {"end": 520.44, "start": 519.88, "text": "improve"}, {"end": 520.92, "start": 520.44, "text": "the"}, {"end": 521.6, "start": 520.92, "text": "performance"}, {"end": 521.68, "start": 521.6, "text": "of"}, {"end": 521.88, "start": 521.68, "text": "time"}, {"end": 522.12, "start": 521.88, "text": "series"}, {"end": 522.56, "start": 522.12, "text": "foundation"}, {"end": 523.08, "start": 522.56, "text": "models,"}, {"end": 523.36, "start": 523.08, "text": "we"}, {"end": 524.04, "start": 523.36, "text": "investigate"}, {"end": 524.52, "start": 524.04, "text": "several"}, {"end": 525.04, "start": 524.52, "text": "key"}, {"end": 525.32, "start": 525.04, "text": "features"}, {"end": 525.56, "start": 525.32, "text": "that"}, {"end": 525.8, "start": 525.56, "text": "we"}, {"end": 526.08, "start": 525.8, "text": "think"}, {"end": 526.12, "start": 526.08, "text": "that"}, {"end": 526.44, "start": 526.12, "text": "we"}, {"end": 526.96, "start": 526.44, "text": "should"}, {"end": 527.52, "start": 526.96, "text": "explore"}, {"end": 527.52, "start": 527.52, "text": "in"}, {"end": 527.96, "start": 527.52, "text": "the"}, {"end": 528.52, "start": 527.96, "text": "future"}, {"end": 528.72, "start": 528.52, "text": "for"}, {"end": 529.08, "start": 528.72, "text": "building"}, {"end": 531.72, "start": 529.08, "text": "analytics."}, {"end": 532.16, "start": 531.72, "text": "So"}, {"end": 532.96, "start": 532.16, "text": "first,"}, {"end": 533.88, "start": 532.96, "text": "unlike"}, {"end": 534.32, "start": 533.88, "text": "language"}, {"end": 534.84, "start": 534.32, "text": "models,"}, {"end": 535.04, "start": 534.84, "text": "we"}, {"end": 535.6, "start": 535.04, "text": "found"}, {"end": 535.68, "start": 535.6, "text": "that"}, {"end": 536.04, "start": 535.68, "text": "most"}, {"end": 536.04, "start": 536.04, "text": "of"}, {"end": 536.48, "start": 536.04, "text": "current"}, {"end": 536.76, "start": 536.48, "text": "time"}, {"end": 537.04, "start": 536.76, "text": "series"}, {"end": 537.52, "start": 537.04, "text": "foundation"}, {"end": 538.08, "start": 537.52, "text": "models"}, {"end": 538.2, "start": 538.08, "text": "do"}, {"end": 538.64, "start": 538.2, "text": "not"}, {"end": 539.16, "start": 538.64, "text": "incorporate"}, {"end": 539.52, "start": 539.16, "text": "the"}, {"end": 539.96, "start": 539.52, "text": "importance"}], "text": " we found that currently these time series foundation models cannot fully meet our needs for building analytics. So, and to further improve the performance of time series foundation models, we investigate several key features that we think that we should explore in the future for building analytics. So first, unlike language models, we found that most of current time series foundation models do not incorporate the importance"}, {"chunks": [{"end": 541.04, "start": 540.0, "text": "context"}, {"end": 541.68, "start": 541.04, "text": "information"}, {"end": 542.24, "start": 541.68, "text": "such"}, {"end": 542.28, "start": 542.24, "text": "as"}, {"end": 542.36, "start": 542.28, "text": "the"}, {"end": 542.76, "start": 542.36, "text": "physical"}, {"end": 543.84, "start": 542.76, "text": "process,"}, {"end": 544.76, "start": 543.84, "text": "locations,"}, {"end": 545.04, "start": 544.76, "text": "or"}, {"end": 545.32, "start": 545.04, "text": "sensor"}, {"end": 546.56, "start": 545.32, "text": "characteristics."}, {"end": 546.92, "start": 546.56, "text": "And"}, {"end": 547.12, "start": 546.92, "text": "we"}, {"end": 547.16, "start": 547.12, "text": "think"}, {"end": 547.48, "start": 547.16, "text": "that"}, {"end": 548.28, "start": 547.48, "text": "incorporating"}, {"end": 548.6, "start": 548.28, "text": "this"}, {"end": 549.32, "start": 548.6, "text": "context"}, {"end": 550.0, "start": 549.32, "text": "information"}, {"end": 550.2, "start": 550.0, "text": "in"}, {"end": 550.52, "start": 550.2, "text": "the"}, {"end": 551.16, "start": 550.52, "text": "model"}, {"end": 551.6, "start": 551.16, "text": "input"}, {"end": 551.84, "start": 551.6, "text": "will"}, {"end": 552.24, "start": 551.84, "text": "have"}, {"end": 553.0, "start": 552.24, "text": "potential"}, {"end": 553.32, "start": 553.0, "text": "to"}, {"end": 554.16, "start": 553.32, "text": "significantly"}, {"end": 554.76, "start": 554.16, "text": "enhance"}, {"end": 555.12, "start": 554.76, "text": "the"}, {"end": 557.28, "start": 555.12, "text": "performance."}, {"end": 558.16, "start": 557.28, "text": "And"}, {"end": 558.92, "start": 558.16, "text": "second,"}, {"end": 559.52, "start": 558.92, "text": "beyond"}, {"end": 559.76, "start": 559.52, "text": "data"}, {"end": 560.56, "start": 559.76, "text": "forecasting,"}, {"end": 561.0, "start": 560.56, "text": "we"}, {"end": 561.44, "start": 561.0, "text": "think"}, {"end": 561.92, "start": 561.44, "text": "that"}, {"end": 562.24, "start": 561.92, "text": "time"}, {"end": 562.48, "start": 562.24, "text": "series"}, {"end": 562.96, "start": 562.48, "text": "foundation"}, {"end": 563.52, "start": 562.96, "text": "models"}, {"end": 563.64, "start": 563.52, "text": "should"}, {"end": 564.32, "start": 563.64, "text": "also"}, {"end": 564.64, "start": 564.32, "text": "have"}, {"end": 564.8, "start": 564.64, "text": "the"}, {"end": 565.44, "start": 564.8, "text": "capability"}, {"end": 565.92, "start": 565.44, "text": "to"}, {"end": 566.2, "start": 565.92, "text": "handle"}, {"end": 566.44, "start": 566.2, "text": "a"}, {"end": 567.2, "start": 566.44, "text": "variety"}, {"end": 567.28, "start": 567.2, "text": "of"}, {"end": 567.52, "start": 567.28, "text": "data"}, {"end": 568.08, "start": 567.52, "text": "sets"}, {"end": 568.4, "start": 568.08, "text": "such"}, {"end": 568.64, "start": 568.4, "text": "as"}, {"end": 569.2, "start": 568.64, "text": "anomaly"}, {"end": 569.96, "start": 569.2, "text": "detection,"}], "text": " context information such as the physical process, locations, or sensor characteristics. And we think that incorporating this context information in the model input will have potential to significantly enhance the performance. And second, beyond data forecasting, we think that time series foundation models should also have the capability to handle a variety of data sets such as anomaly detection,"}, {"chunks": [{"end": 570.96, "start": 570.0, "text": "classification,"}, {"end": 571.12, "start": 570.96, "text": "or"}, {"end": 571.56, "start": 571.12, "text": "even"}, {"end": 572.24, "start": 571.56, "text": "high-level"}, {"end": 572.44, "start": 572.24, "text": "reasoning"}, {"end": 574.92, "start": 572.44, "text": "tasks."}, {"end": 575.52, "start": 574.92, "text": "And"}, {"end": 575.8, "start": 575.52, "text": "finally,"}, {"end": 575.88, "start": 575.8, "text": "we"}, {"end": 576.72, "start": 575.88, "text": "found"}, {"end": 577.08, "start": 576.72, "text": "that"}, {"end": 577.48, "start": 577.08, "text": "most"}, {"end": 577.52, "start": 577.48, "text": "of"}, {"end": 578.08, "start": 577.52, "text": "current"}, {"end": 578.84, "start": 578.08, "text": "TSFMs"}, {"end": 578.96, "start": 578.84, "text": "can"}, {"end": 579.52, "start": 578.96, "text": "only"}, {"end": 579.8, "start": 579.52, "text": "handle"}, {"end": 580.28, "start": 579.8, "text": "single"}, {"end": 581.36, "start": 580.28, "text": "attributes,"}, {"end": 581.52, "start": 581.36, "text": "but"}, {"end": 581.76, "start": 581.52, "text": "we"}, {"end": 582.04, "start": 581.76, "text": "think"}, {"end": 582.96, "start": 582.04, "text": "that"}, {"end": 583.12, "start": 582.96, "text": "it's"}, {"end": 583.4, "start": 583.12, "text": "very"}, {"end": 583.88, "start": 583.4, "text": "important"}, {"end": 583.88, "start": 583.88, "text": "to"}, {"end": 584.28, "start": 583.88, "text": "explore"}, {"end": 584.84, "start": 584.28, "text": "the"}, {"end": 585.72, "start": 584.84, "text": "covariance"}, {"end": 585.96, "start": 585.72, "text": "of"}, {"end": 586.6, "start": 585.96, "text": "multiple"}, {"end": 587.16, "start": 586.6, "text": "attributes,"}, {"end": 587.96, "start": 587.16, "text": "especially"}, {"end": 588.08, "start": 587.96, "text": "in"}, {"end": 588.48, "start": 588.08, "text": "building"}, {"end": 589.12, "start": 588.48, "text": "analytics,"}, {"end": 589.4, "start": 589.12, "text": "such"}, {"end": 589.76, "start": 589.4, "text": "as"}, {"end": 590.72, "start": 589.76, "text": "indoor-outdoor"}, {"end": 591.64, "start": 590.72, "text": "temperatures,"}, {"end": 591.84, "start": 591.64, "text": "as"}, {"end": 591.88, "start": 591.84, "text": "well"}, {"end": 592.04, "start": 591.88, "text": "as"}, {"end": 592.48, "start": 592.04, "text": "solar"}, {"end": 592.8, "start": 592.48, "text": "gains,"}, {"end": 593.0, "start": 592.8, "text": "et"}, {"end": 593.44, "start": 593.0, "text": "cetera."}, {"end": 596.64, "start": 593.44, "text": "So"}, {"end": 596.88, "start": 596.64, "text": "to"}, {"end": 597.36, "start": 596.88, "text": "enhance"}, {"end": 597.52, "start": 597.36, "text": "the"}, {"end": 598.16, "start": 597.52, "text": "performance"}, {"end": 598.32, "start": 598.16, "text": "of"}, {"end": 598.64, "start": 598.32, "text": "time"}, {"end": 598.92, "start": 598.64, "text": "series"}, {"end": 599.36, "start": 598.92, "text": "foundation"}, {"end": 599.88, "start": 599.36, "text": "models"}, {"end": 599.96, "start": 599.88, "text": "in"}], "text": " classification, or even high-level reasoning tasks. And finally, we found that most of current TSFMs can only handle single attributes, but we think that it's very important to explore the covariance of multiple attributes, especially in building analytics, such as indoor-outdoor temperatures, as well as solar gains, et cetera. So to enhance the performance of time series foundation models in"}, {"chunks": [{"end": 600.16, "start": 600.0, "text": "these"}, {"end": 600.48, "start": 600.16, "text": "key"}, {"end": 600.96, "start": 600.48, "text": "areas,"}, {"end": 600.96, "start": 600.96, "text": "we"}, {"end": 601.44, "start": 600.96, "text": "would"}, {"end": 601.84, "start": 601.44, "text": "like"}, {"end": 602.08, "start": 601.84, "text": "to"}, {"end": 602.68, "start": 602.08, "text": "encourage"}, {"end": 602.84, "start": 602.68, "text": "the"}, {"end": 603.4, "start": 602.84, "text": "community"}, {"end": 604.0, "start": 603.4, "text": "efforts"}, {"end": 604.0, "start": 604.0, "text": "in"}, {"end": 604.2, "start": 604.0, "text": "the"}, {"end": 604.6, "start": 604.2, "text": "following"}, {"end": 605.44, "start": 604.6, "text": "areas,"}, {"end": 605.8, "start": 605.44, "text": "including"}, {"end": 606.12, "start": 605.8, "text": "the"}, {"end": 606.36, "start": 606.12, "text": "data"}, {"end": 607.24, "start": 606.36, "text": "sharing,"}, {"end": 608.12, "start": 607.24, "text": "architecture"}, {"end": 608.96, "start": 608.12, "text": "innovation,"}, {"end": 609.28, "start": 608.96, "text": "is"}, {"end": 610.16, "start": 609.28, "text": "systematic"}, {"end": 611.16, "start": 610.16, "text": "benchmarking"}, {"end": 611.48, "start": 611.16, "text": "as"}, {"end": 611.48, "start": 611.48, "text": "well"}, {"end": 611.56, "start": 611.48, "text": "as"}, {"end": 612.12, "start": 611.56, "text": "resource"}, {"end": 612.8, "start": 612.12, "text": "sharing."}, {"end": 613.04, "start": 612.8, "text": "So"}, {"end": 613.72, "start": 613.04, "text": "that's"}, {"end": 613.88, "start": 613.72, "text": "all"}, {"end": 614.4, "start": 613.88, "text": "for"}, {"end": 614.4, "start": 614.4, "text": "the"}, {"end": 614.72, "start": 614.4, "text": "talk."}, {"end": 615.2, "start": 614.72, "text": "So"}, {"end": 615.28, "start": 615.2, "text": "for"}, {"end": 615.48, "start": 615.28, "text": "more"}, {"end": 615.92, "start": 615.48, "text": "details,"}, {"end": 616.24, "start": 615.92, "text": "please"}, {"end": 616.48, "start": 616.24, "text": "refer"}, {"end": 616.64, "start": 616.48, "text": "to"}, {"end": 616.96, "start": 616.64, "text": "our"}, {"end": 617.52, "start": 616.96, "text": "paper"}, {"end": 618.08, "start": 617.52, "text": "and"}, {"end": 618.32, "start": 618.08, "text": "our"}, {"end": 618.76, "start": 618.32, "text": "project"}, {"end": 620.12, "start": 618.76, "text": "page."}, {"end": 620.64, "start": 620.12, "text": "Thank"}, {"end": 621.2, "start": 620.64, "text": "you."}, {"end": 623.12, "start": 621.2, "text": "Thank"}, {"end": 623.6, "start": 623.12, "text": "you,"}, {"end": 623.84, "start": 623.6, "text": "Prof."}, {"end": 624.84, "start": 623.84, "text": "Xiaomin."}, {"end": 624.96, "start": 624.84, "text": "We"}, {"end": 625.2, "start": 624.96, "text": "have"}, {"end": 626.04, "start": 625.2, "text": "questions"}, {"end": 626.2, "start": 626.04, "text": "from"}, {"end": 626.56, "start": 626.2, "text": "the"}, {"end": 627.28, "start": 626.56, "text": "audience?"}, {"end": 627.84, "start": 627.28, "text": "Oh,"}, {"end": 629.96, "start": 627.84, "text": "yes."}], "text": " these key areas, we would like to encourage the community efforts in the following areas, including the data sharing, architecture innovation, is systematic benchmarking as well as resource sharing. So that's all for the talk. So for more details, please refer to our paper and our project page. Thank you. Thank you, Prof. Xiaomin. We have questions from the audience? Oh, yes."}, {"chunks": [{"end": 631.84, "start": 630.0, "text": "Very"}, {"end": 632.16, "start": 631.84, "text": "nice"}, {"end": 633.32, "start": 632.16, "text": "presentation."}, {"end": 634.24, "start": 633.32, "text": "Very"}, {"end": 634.88, "start": 634.24, "text": "interesting"}, {"end": 635.32, "start": 634.88, "text": "topic"}, {"end": 635.52, "start": 635.32, "text": "and"}, {"end": 635.72, "start": 635.52, "text": "our"}, {"end": 636.08, "start": 635.72, "text": "team"}, {"end": 636.28, "start": 636.08, "text": "are"}, {"end": 636.68, "start": 636.28, "text": "still"}, {"end": 636.8, "start": 636.68, "text": "working"}, {"end": 637.04, "start": 636.8, "text": "on"}, {"end": 637.8, "start": 637.04, "text": "this."}, {"end": 638.92, "start": 637.8, "text": "The"}, {"end": 639.32, "start": 638.92, "text": "first"}, {"end": 640.16, "start": 639.32, "text": "question"}, {"end": 640.96, "start": 640.16, "text": "is"}, {"end": 641.36, "start": 640.96, "text": "what"}, {"end": 641.76, "start": 641.36, "text": "do"}, {"end": 642.08, "start": 641.76, "text": "you"}, {"end": 642.44, "start": 642.08, "text": "think"}, {"end": 643.24, "start": 642.44, "text": "about"}, {"end": 643.44, "start": 643.24, "text": "in"}, {"end": 643.52, "start": 643.44, "text": "the"}, {"end": 643.84, "start": 643.52, "text": "building"}, {"end": 644.6, "start": 643.84, "text": "analytics"}, {"end": 645.16, "start": 644.6, "text": "or"}, {"end": 645.44, "start": 645.16, "text": "the"}, {"end": 645.68, "start": 645.44, "text": "load"}, {"end": 646.48, "start": 645.68, "text": "forecasting,"}, {"end": 647.0, "start": 646.48, "text": "what"}, {"end": 647.0, "start": 647.0, "text": "do"}, {"end": 647.0, "start": 647.0, "text": "you"}, {"end": 647.04, "start": 647.0, "text": "think"}, {"end": 647.36, "start": 647.04, "text": "about"}, {"end": 648.12, "start": 647.36, "text": "using"}, {"end": 648.56, "start": 648.12, "text": "the"}, {"end": 649.0, "start": 648.56, "text": "time"}, {"end": 649.32, "start": 649.0, "text": "series"}, {"end": 649.68, "start": 649.32, "text": "foundation"}, {"end": 650.68, "start": 649.68, "text": "model"}, {"end": 650.88, "start": 650.68, "text": "and"}, {"end": 651.48, "start": 650.88, "text": "using"}, {"end": 651.92, "start": 651.48, "text": "a"}, {"end": 652.32, "start": 651.92, "text": "big"}, {"end": 652.84, "start": 652.32, "text": "ASTM"}, {"end": 653.16, "start": 652.84, "text": "model"}, {"end": 653.56, "start": 653.16, "text": "trained"}, {"end": 653.92, "start": 653.56, "text": "by"}, {"end": 654.12, "start": 653.92, "text": "for"}, {"end": 654.4, "start": 654.12, "text": "example"}, {"end": 654.56, "start": 654.4, "text": "one"}, {"end": 655.08, "start": 654.56, "text": "thousand"}, {"end": 655.16, "start": 655.08, "text": "of"}, {"end": 655.32, "start": 655.16, "text": "buildings?"}, {"end": 655.68, "start": 655.32, "text": "These"}, {"end": 656.36, "start": 655.68, "text": "two"}, {"end": 656.72, "start": 656.36, "text": "models,"}, {"end": 657.16, "start": 656.72, "text": "what"}, {"end": 657.24, "start": 657.16, "text": "do"}, {"end": 657.8, "start": 657.24, "text": "you"}, {"end": 658.04, "start": 657.8, "text": "think"}, {"end": 658.2, "start": 658.04, "text": "about"}, {"end": 659.0, "start": 658.2, "text": "them?"}, {"end": 659.52, "start": 659.0, "text": "No"}, {"end": 659.88, "start": 659.52, "text": "matter"}, {"end": 659.96, "start": 659.88, "text": "in"}], "text": " Very nice presentation. Very interesting topic and our team are still working on this. The first question is what do you think about in the building analytics or the load forecasting, what do you think about using the time series foundation model and using a big ASTM model trained by for example one thousand of buildings? These two models, what do you think about them? No matter in"}, {"chunks": [{"end": 660.16, "start": 660.0, "text": "the"}, {"end": 660.4, "start": 660.16, "text": "zero"}, {"end": 660.72, "start": 660.4, "text": "shot"}, {"end": 660.88, "start": 660.72, "text": "or"}, {"end": 661.04, "start": 660.88, "text": "few"}, {"end": 661.44, "start": 661.04, "text": "shots"}, {"end": 661.6, "start": 661.44, "text": "in"}, {"end": 661.92, "start": 661.6, "text": "manner"}, {"end": 662.2, "start": 661.92, "text": "to"}, {"end": 662.76, "start": 662.2, "text": "inferencing"}, {"end": 662.88, "start": 662.76, "text": "a"}, {"end": 663.2, "start": 662.88, "text": "target"}, {"end": 664.68, "start": 663.2, "text": "building?"}, {"end": 665.0, "start": 664.68, "text": "Yeah,"}, {"end": 665.04, "start": 665.0, "text": "very"}, {"end": 665.2, "start": 665.04, "text": "great"}, {"end": 665.76, "start": 665.2, "text": "questions."}, {"end": 666.24, "start": 665.76, "text": "First,"}, {"end": 666.72, "start": 666.24, "text": "I"}, {"end": 667.08, "start": 666.72, "text": "think"}, {"end": 667.28, "start": 667.08, "text": "it"}, {"end": 667.8, "start": 667.28, "text": "depends"}, {"end": 668.28, "start": 667.8, "text": "on"}, {"end": 668.48, "start": 668.28, "text": "the"}, {"end": 669.16, "start": 668.48, "text": "definition"}, {"end": 669.2, "start": 669.16, "text": "of"}, {"end": 669.6, "start": 669.2, "text": "foundation"}, {"end": 670.12, "start": 669.6, "text": "models."}, {"end": 670.4, "start": 670.12, "text": "For"}, {"end": 671.08, "start": 670.4, "text": "example,"}, {"end": 671.16, "start": 671.08, "text": "in"}, {"end": 671.48, "start": 671.16, "text": "my"}, {"end": 671.76, "start": 671.48, "text": "understanding,"}, {"end": 672.04, "start": 671.76, "text": "as"}, {"end": 672.64, "start": 672.04, "text": "long"}, {"end": 673.24, "start": 672.64, "text": "as"}, {"end": 673.4, "start": 673.24, "text": "your"}, {"end": 673.72, "start": 673.4, "text": "model"}, {"end": 673.92, "start": 673.72, "text": "is"}, {"end": 674.2, "start": 673.92, "text": "trained"}, {"end": 674.64, "start": 674.2, "text": "on"}, {"end": 675.28, "start": 674.64, "text": "a"}, {"end": 675.96, "start": 675.28, "text": "large,"}, {"end": 676.48, "start": 675.96, "text": "large"}, {"end": 677.24, "start": 676.48, "text": "set"}, {"end": 677.4, "start": 677.24, "text": "of"}, {"end": 678.32, "start": 677.4, "text": "datasets"}, {"end": 678.6, "start": 678.32, "text": "for"}, {"end": 678.96, "start": 678.6, "text": "and"}, {"end": 679.36, "start": 678.96, "text": "even"}, {"end": 679.8, "start": 679.36, "text": "and"}, {"end": 679.88, "start": 679.8, "text": "usually"}, {"end": 680.0, "start": 679.88, "text": "in"}, {"end": 680.36, "start": 680.0, "text": "an"}, {"end": 681.44, "start": 680.36, "text": "unsupervised"}, {"end": 681.92, "start": 681.44, "text": "manner"}, {"end": 682.08, "start": 681.92, "text": "for"}, {"end": 682.56, "start": 682.08, "text": "forecasting"}, {"end": 682.84, "start": 682.56, "text": "tasks,"}, {"end": 683.24, "start": 682.84, "text": "I"}, {"end": 683.52, "start": 683.24, "text": "think"}, {"end": 683.56, "start": 683.52, "text": "in"}, {"end": 683.92, "start": 683.56, "text": "that"}, {"end": 684.4, "start": 683.92, "text": "case,"}, {"end": 684.52, "start": 684.4, "text": "that"}, {"end": 684.64, "start": 684.52, "text": "model"}, {"end": 684.84, "start": 684.64, "text": "could"}, {"end": 685.16, "start": 684.84, "text": "be"}, {"end": 685.36, "start": 685.16, "text": "named"}, {"end": 685.88, "start": 685.36, "text": "as"}, {"end": 686.16, "start": 685.88, "text": "a"}, {"end": 686.68, "start": 686.16, "text": "foundation"}, {"end": 687.24, "start": 686.68, "text": "model."}, {"end": 688.0, "start": 687.24, "text": "So"}, {"end": 688.28, "start": 688.0, "text": "I"}, {"end": 688.92, "start": 688.28, "text": "think"}, {"end": 689.48, "start": 688.92, "text": "that's"}, {"end": 689.56, "start": 689.48, "text": "a,"}, {"end": 689.92, "start": 689.56, "text": "that's"}, {"end": 689.96, "start": 689.92, "text": "a,"}], "text": " the zero shot or few shots in manner to inferencing a target building? Yeah, very great questions. First, I think it depends on the definition of foundation models. For example, in my understanding, as long as your model is trained on a large, large set of datasets for and even and usually in an unsupervised manner for forecasting tasks, I think in that case, that model could be named as a foundation model. So I think that's a, that's a,"}, {"chunks": [{"end": 691.24, "start": 690.0, "text": "direction"}, {"end": 691.4, "start": 691.24, "text": "or"}, {"end": 691.72, "start": 691.4, "text": "there's"}, {"end": 691.8, "start": 691.72, "text": "a"}, {"end": 692.32, "start": 691.8, "text": "potential"}, {"end": 692.52, "start": 692.32, "text": "to"}, {"end": 693.12, "start": 692.52, "text": "developing"}, {"end": 693.36, "start": 693.12, "text": "a"}, {"end": 694.8, "start": 693.36, "text": "generalizable"}, {"end": 695.24, "start": 694.8, "text": "foundation"}, {"end": 695.68, "start": 695.24, "text": "models"}, {"end": 695.8, "start": 695.68, "text": "in"}, {"end": 696.16, "start": 695.8, "text": "building"}, {"end": 697.28, "start": 696.16, "text": "analytics."}, {"end": 698.12, "start": 697.28, "text": "Yeah,"}, {"end": 701.4, "start": 698.12, "text": "yeah."}, {"end": 701.84, "start": 701.4, "text": "But"}, {"end": 702.8, "start": 701.84, "text": "the"}, {"end": 703.68, "start": 702.8, "text": "existing"}, {"end": 704.2, "start": 703.68, "text": "foundation"}, {"end": 704.72, "start": 704.2, "text": "models,"}, {"end": 705.92, "start": 704.72, "text": "they"}, {"end": 706.2, "start": 705.92, "text": "involve"}, {"end": 706.72, "start": 706.2, "text": "the"}, {"end": 707.28, "start": 706.72, "text": "knowledge"}, {"end": 707.8, "start": 707.28, "text": "I"}, {"end": 708.36, "start": 707.8, "text": "think"}, {"end": 708.64, "start": 708.36, "text": "maybe"}, {"end": 708.92, "start": 708.64, "text": "not"}, {"end": 709.2, "start": 708.92, "text": "useful"}, {"end": 709.52, "start": 709.2, "text": "for"}, {"end": 709.8, "start": 709.52, "text": "our"}, {"end": 710.12, "start": 709.8, "text": "task."}, {"end": 710.52, "start": 710.12, "text": "For"}, {"end": 710.64, "start": 710.52, "text": "example,"}, {"end": 711.32, "start": 710.64, "text": "they're"}, {"end": 711.6, "start": 711.32, "text": "trained"}, {"end": 711.88, "start": 711.6, "text": "by"}, {"end": 712.08, "start": 711.88, "text": "the"}, {"end": 712.28, "start": 712.08, "text": "medical"}, {"end": 712.72, "start": 712.28, "text": "or"}, {"end": 713.16, "start": 712.72, "text": "the"}, {"end": 713.92, "start": 713.16, "text": "financial"}, {"end": 714.2, "start": 713.92, "text": "data"}, {"end": 714.64, "start": 714.2, "text": "in"}, {"end": 714.84, "start": 714.64, "text": "it."}, {"end": 715.48, "start": 714.84, "text": "So"}, {"end": 716.04, "start": 715.48, "text": "what"}, {"end": 716.64, "start": 716.04, "text": "do"}, {"end": 716.92, "start": 716.64, "text": "you"}, {"end": 717.2, "start": 716.92, "text": "think"}, {"end": 717.6, "start": 717.2, "text": "about"}, {"end": 717.92, "start": 717.6, "text": "it?"}, {"end": 718.44, "start": 717.92, "text": "Do"}, {"end": 718.76, "start": 718.44, "text": "we"}, {"end": 719.0, "start": 718.76, "text": "need"}, {"end": 719.32, "start": 719.0, "text": "to"}, {"end": 719.68, "start": 719.32, "text": "de-knowledge"}, {"end": 719.96, "start": 719.68, "text": "this"}], "text": " direction or there's a potential to developing a generalizable foundation models in building analytics. Yeah, yeah. But the existing foundation models, they involve the knowledge I think maybe not useful for our task. For example, they're trained by the medical or the financial data in it. So what do you think about it? Do we need to de-knowledge this"}, {"chunks": [{"end": 721.12, "start": 720.0, "text": "knowledge"}, {"end": 721.36, "start": 721.12, "text": "from"}, {"end": 721.8, "start": 721.36, "text": "because"}, {"end": 722.52, "start": 721.8, "text": "they"}, {"end": 722.68, "start": 722.52, "text": "are"}, {"end": 723.24, "start": 722.68, "text": "not"}, {"end": 723.52, "start": 723.24, "text": "really"}, {"end": 723.64, "start": 723.52, "text": "to"}, {"end": 723.8, "start": 723.64, "text": "our"}, {"end": 723.8, "start": 723.8, "text": "task."}, {"end": 724.16, "start": 723.8, "text": "That's"}, {"end": 725.0, "start": 724.16, "text": "true."}, {"end": 725.68, "start": 725.0, "text": "That's"}, {"end": 726.24, "start": 725.68, "text": "true."}, {"end": 726.52, "start": 726.24, "text": "Yeah."}, {"end": 727.08, "start": 726.52, "text": "Yeah."}, {"end": 727.32, "start": 727.08, "text": "I"}, {"end": 727.56, "start": 727.32, "text": "agree"}, {"end": 727.84, "start": 727.56, "text": "that"}, {"end": 728.56, "start": 727.84, "text": "actually"}, {"end": 728.96, "start": 728.56, "text": "our"}, {"end": 729.64, "start": 728.96, "text": "general"}, {"end": 730.32, "start": 729.64, "text": "purpose"}, {"end": 731.48, "start": 730.32, "text": "foundation"}, {"end": 731.88, "start": 731.48, "text": "models"}, {"end": 732.08, "start": 731.88, "text": "may"}, {"end": 732.6, "start": 732.08, "text": "not"}, {"end": 732.92, "start": 732.6, "text": "be"}, {"end": 733.4, "start": 732.92, "text": "useful"}, {"end": 733.68, "start": 733.4, "text": "for"}, {"end": 734.12, "start": 733.68, "text": "specific"}, {"end": 734.44, "start": 734.12, "text": "types"}, {"end": 734.72, "start": 734.44, "text": "such"}, {"end": 734.96, "start": 734.72, "text": "as"}, {"end": 735.28, "start": 734.96, "text": "building"}, {"end": 735.92, "start": 735.28, "text": "analytics."}, {"end": 736.08, "start": 735.92, "text": "So"}, {"end": 736.32, "start": 736.08, "text": "we"}, {"end": 736.84, "start": 736.32, "text": "actually"}, {"end": 737.6, "start": 736.84, "text": "encourage"}, {"end": 737.72, "start": 737.6, "text": "the"}, {"end": 738.16, "start": 737.72, "text": "community,"}, {"end": 738.56, "start": 738.16, "text": "for"}, {"end": 739.04, "start": 738.56, "text": "example,"}, {"end": 739.4, "start": 739.04, "text": "to"}, {"end": 740.76, "start": 739.4, "text": "build"}, {"end": 741.68, "start": 740.76, "text": "building"}, {"end": 742.48, "start": 741.68, "text": "specific"}, {"end": 743.04, "start": 742.48, "text": "foundation"}, {"end": 743.64, "start": 743.04, "text": "models,"}, {"end": 744.04, "start": 743.64, "text": "which"}, {"end": 744.48, "start": 744.04, "text": "would"}, {"end": 745.08, "start": 744.48, "text": "actually"}, {"end": 745.44, "start": 745.08, "text": "have"}, {"end": 745.56, "start": 745.44, "text": "a"}, {"end": 745.72, "start": 745.56, "text": "better"}, {"end": 746.56, "start": 745.72, "text": "performance"}, {"end": 746.64, "start": 746.56, "text": "in"}, {"end": 746.92, "start": 746.64, "text": "building"}, {"end": 747.52, "start": 746.92, "text": "related"}, {"end": 748.72, "start": 747.52, "text": "tasks."}, {"end": 749.52, "start": 748.72, "text": "Yes,"}, {"end": 749.64, "start": 749.52, "text": "I"}, {"end": 749.8, "start": 749.64, "text": "agree"}, {"end": 749.96, "start": 749.8, "text": "there."}], "text": " knowledge from because they are not really to our task. That's true. That's true. Yeah. Yeah. I agree that actually our general purpose foundation models may not be useful for specific types such as building analytics. So we actually encourage the community, for example, to build building specific foundation models, which would actually have a better performance in building related tasks. Yes, I agree there."}, {"chunks": [{"end": 750.16, "start": 750.0, "text": "Thank"}, {"end": 750.32, "start": 750.16, "text": "you."}, {"end": 750.48, "start": 750.32, "text": "Thank"}, {"end": 750.96, "start": 750.48, "text": "you."}, {"end": 751.16, "start": 750.96, "text": "Thank"}, {"end": 751.52, "start": 751.16, "text": "you"}, {"end": 751.76, "start": 751.52, "text": "for"}, {"end": 751.92, "start": 751.76, "text": "your"}, {"end": 752.56, "start": 751.92, "text": "question."}, {"end": 753.0, "start": 752.56, "text": "We"}, {"end": 753.12, "start": 753.0, "text": "have"}, {"end": 753.4, "start": 753.12, "text": "time"}, {"end": 753.68, "start": 753.4, "text": "for"}, {"end": 753.76, "start": 753.68, "text": "more"}, {"end": 754.2, "start": 753.76, "text": "questions."}, {"end": 754.56, "start": 754.2, "text": "Oh,"}, {"end": 754.92, "start": 754.56, "text": "Sammy."}, {"end": 755.6, "start": 754.92, "text": "Hi,"}, {"end": 756.84, "start": 755.6, "text": "interesting"}, {"end": 757.56, "start": 756.84, "text": "talk."}, {"end": 757.8, "start": 757.56, "text": "Can"}, {"end": 757.88, "start": 757.8, "text": "you"}, {"end": 758.36, "start": 757.88, "text": "please"}, {"end": 758.44, "start": 758.36, "text": "go"}, {"end": 759.32, "start": 758.44, "text": "to"}, {"end": 759.88, "start": 759.32, "text": "the"}, {"end": 760.6, "start": 759.88, "text": "slide"}, {"end": 761.04, "start": 760.6, "text": "where"}, {"end": 761.4, "start": 761.04, "text": "you"}, {"end": 761.8, "start": 761.4, "text": "have"}, {"end": 762.0, "start": 761.8, "text": "come"}, {"end": 762.24, "start": 762.0, "text": "back"}, {"end": 762.68, "start": 762.24, "text": "to"}, {"end": 763.12, "start": 762.68, "text": "model"}, {"end": 763.88, "start": 763.12, "text": "performance?"}, {"end": 764.04, "start": 763.88, "text": "This"}, {"end": 764.72, "start": 764.04, "text": "performance?"}, {"end": 765.08, "start": 764.72, "text": "Sure."}, {"end": 765.24, "start": 765.08, "text": "The"}, {"end": 765.76, "start": 765.24, "text": "previous"}, {"end": 766.72, "start": 765.76, "text": "one."}, {"end": 767.88, "start": 766.72, "text": "Okay."}, {"end": 768.28, "start": 767.88, "text": "So"}, {"end": 768.72, "start": 768.28, "text": "I"}, {"end": 769.08, "start": 768.72, "text": "think"}, {"end": 769.48, "start": 769.08, "text": "that"}, {"end": 769.72, "start": 769.48, "text": "both"}, {"end": 769.96, "start": 769.72, "text": "the"}, {"end": 770.56, "start": 769.96, "text": "data"}, {"end": 770.88, "start": 770.56, "text": "set,"}, {"end": 771.84, "start": 770.88, "text": "you"}, {"end": 772.36, "start": 771.84, "text": "have"}, {"end": 773.0, "start": 772.36, "text": "considered"}, {"end": 773.24, "start": 773.0, "text": "multiple"}, {"end": 773.96, "start": 773.24, "text": "buildings"}, {"end": 774.12, "start": 773.96, "text": "I"}, {"end": 774.76, "start": 774.12, "text": "assume,"}, {"end": 774.92, "start": 774.76, "text": "right?"}, {"end": 775.2, "start": 774.92, "text": "Many"}, {"end": 775.84, "start": 775.2, "text": "buildings,"}, {"end": 776.2, "start": 775.84, "text": "right?"}, {"end": 776.28, "start": 776.2, "text": "So"}, {"end": 776.56, "start": 776.28, "text": "the"}, {"end": 777.24, "start": 776.56, "text": "RMSC"}, {"end": 777.72, "start": 777.24, "text": "is"}, {"end": 778.12, "start": 777.72, "text": "like"}, {"end": 778.84, "start": 778.12, "text": "300"}, {"end": 779.96, "start": 778.84, "text": "watts."}], "text": " Thank you. Thank you. Thank you for your question. We have time for more questions. Oh, Sammy. Hi, interesting talk. Can you please go to the slide where you have come back to model performance? This performance? Sure. The previous one. Okay. So I think that both the data set, you have considered multiple buildings I assume, right? Many buildings, right? So the RMSC is like 300 watts."}, {"chunks": [{"end": 780.56, "start": 780.0, "text": "Is"}, {"end": 780.88, "start": 780.56, "text": "it"}, {"end": 781.24, "start": 780.88, "text": "because"}, {"end": 781.28, "start": 781.24, "text": "the"}, {"end": 781.52, "start": 781.28, "text": "different"}, {"end": 781.88, "start": 781.52, "text": "buildings"}, {"end": 782.12, "start": 781.88, "text": "the"}, {"end": 782.24, "start": 782.12, "text": "energy"}, {"end": 782.92, "start": 782.24, "text": "consumption"}, {"end": 783.32, "start": 782.92, "text": "will"}, {"end": 783.68, "start": 783.32, "text": "be"}, {"end": 784.2, "start": 783.68, "text": "varying"}, {"end": 785.16, "start": 784.2, "text": "right?"}, {"end": 785.96, "start": 785.16, "text": "So"}, {"end": 786.36, "start": 785.96, "text": "it's"}, {"end": 786.52, "start": 786.36, "text": "like"}, {"end": 786.52, "start": 786.52, "text": "how"}, {"end": 786.56, "start": 786.52, "text": "you"}, {"end": 786.92, "start": 786.56, "text": "consider"}, {"end": 787.16, "start": 786.92, "text": "that"}, {"end": 787.72, "start": 787.16, "text": "normalization"}, {"end": 787.76, "start": 787.72, "text": "or"}, {"end": 788.24, "start": 787.76, "text": "something?"}, {"end": 788.52, "start": 788.24, "text": "That's"}, {"end": 788.92, "start": 788.52, "text": "one"}, {"end": 790.04, "start": 788.92, "text": "part"}, {"end": 790.68, "start": 790.04, "text": "and"}, {"end": 791.28, "start": 790.68, "text": "this"}, {"end": 792.0, "start": 791.28, "text": "RMSE"}, {"end": 792.48, "start": 792.0, "text": "of"}, {"end": 793.16, "start": 792.48, "text": "300"}, {"end": 793.28, "start": 793.16, "text": "or"}, {"end": 793.64, "start": 793.28, "text": "200"}, {"end": 794.0, "start": 793.64, "text": "whatever"}, {"end": 794.04, "start": 794.0, "text": "it"}, {"end": 794.4, "start": 794.04, "text": "is"}, {"end": 794.52, "start": 794.4, "text": "on"}, {"end": 794.56, "start": 794.52, "text": "the"}, {"end": 794.8, "start": 794.56, "text": "right"}, {"end": 794.96, "start": 794.8, "text": "hand."}, {"end": 795.04, "start": 794.96, "text": "Is"}, {"end": 795.2, "start": 795.04, "text": "it"}, {"end": 795.2, "start": 795.2, "text": "an"}, {"end": 795.96, "start": 795.2, "text": "acceptable"}, {"end": 796.6, "start": 795.96, "text": "range"}, {"end": 797.28, "start": 796.6, "text": "or"}, {"end": 798.16, "start": 797.28, "text": "how"}, {"end": 798.88, "start": 798.16, "text": "far"}, {"end": 799.0, "start": 798.88, "text": "it"}, {"end": 799.4, "start": 799.0, "text": "is"}, {"end": 799.44, "start": 799.4, "text": "you"}, {"end": 799.68, "start": 799.44, "text": "know"}, {"end": 800.08, "start": 799.68, "text": "deviating"}, {"end": 800.48, "start": 800.08, "text": "from"}, {"end": 800.52, "start": 800.48, "text": "that"}, {"end": 801.48, "start": 800.52, "text": "baseline?"}, {"end": 801.68, "start": 801.48, "text": "Yeah"}, {"end": 802.12, "start": 801.68, "text": "that's"}, {"end": 802.36, "start": 802.12, "text": "a"}, {"end": 802.64, "start": 802.36, "text": "good"}, {"end": 803.2, "start": 802.64, "text": "point."}, {"end": 803.52, "start": 803.2, "text": "Yes"}, {"end": 804.2, "start": 803.52, "text": "so"}, {"end": 804.92, "start": 804.2, "text": "actually"}, {"end": 805.08, "start": 804.92, "text": "in"}, {"end": 805.4, "start": 805.08, "text": "our"}, {"end": 805.6, "start": 805.4, "text": "current"}, {"end": 805.96, "start": 805.6, "text": "results"}, {"end": 806.08, "start": 805.96, "text": "we"}, {"end": 806.12, "start": 806.08, "text": "do"}, {"end": 806.48, "start": 806.12, "text": "not"}, {"end": 807.04, "start": 806.48, "text": "normalize"}, {"end": 807.28, "start": 807.04, "text": "the"}, {"end": 807.96, "start": 807.28, "text": "results"}, {"end": 808.2, "start": 807.96, "text": "but"}, {"end": 808.76, "start": 808.2, "text": "actually"}, {"end": 809.16, "start": 808.76, "text": "to"}, {"end": 809.64, "start": 809.16, "text": "incorporate"}, {"end": 809.96, "start": 809.64, "text": "the"}], "text": " Is it because the different buildings the energy consumption will be varying right? So it's like how you consider that normalization or something? That's one part and this RMSE of 300 or 200 whatever it is on the right hand. Is it an acceptable range or how far it is you know deviating from that baseline? Yeah that's a good point. Yes so actually in our current results we do not normalize the results but actually to incorporate the"}, {"chunks": [{"end": 811.64, "start": 810.0, "text": "variability"}, {"end": 811.88, "start": 811.64, "text": "of"}, {"end": 812.12, "start": 811.88, "text": "different"}, {"end": 812.44, "start": 812.12, "text": "time"}, {"end": 812.68, "start": 812.44, "text": "series"}, {"end": 813.12, "start": 812.68, "text": "data."}, {"end": 813.44, "start": 813.12, "text": "For"}, {"end": 813.92, "start": 813.44, "text": "example,"}, {"end": 814.08, "start": 813.92, "text": "as"}, {"end": 814.44, "start": 814.08, "text": "we"}, {"end": 815.16, "start": 814.44, "text": "mentioned"}, {"end": 815.84, "start": 815.16, "text": "before,"}, {"end": 816.68, "start": 815.84, "text": "actually"}, {"end": 816.96, "start": 816.68, "text": "this"}, {"end": 817.36, "start": 816.96, "text": "data"}, {"end": 817.48, "start": 817.36, "text": "may"}, {"end": 817.92, "start": 817.48, "text": "have"}, {"end": 818.52, "start": 817.92, "text": "different"}, {"end": 819.12, "start": 818.52, "text": "lengths"}, {"end": 819.52, "start": 819.12, "text": "of"}, {"end": 820.24, "start": 819.52, "text": "input"}, {"end": 821.16, "start": 820.24, "text": "and"}, {"end": 821.6, "start": 821.16, "text": "output"}, {"end": 822.28, "start": 821.6, "text": "data."}, {"end": 822.84, "start": 822.28, "text": "So"}, {"end": 823.48, "start": 822.84, "text": "we"}, {"end": 824.08, "start": 823.48, "text": "actually"}, {"end": 824.2, "start": 824.08, "text": "do"}, {"end": 824.96, "start": 824.2, "text": "not"}, {"end": 825.6, "start": 824.96, "text": "normalize"}, {"end": 826.12, "start": 825.6, "text": "it,"}, {"end": 826.4, "start": 826.12, "text": "but"}, {"end": 826.6, "start": 826.4, "text": "actually"}, {"end": 827.4, "start": 826.6, "text": "incorporate"}, {"end": 828.2, "start": 827.4, "text": "combinations"}, {"end": 828.36, "start": 828.2, "text": "of"}, {"end": 829.0, "start": 828.36, "text": "different"}, {"end": 829.24, "start": 829.0, "text": "input"}, {"end": 830.08, "start": 829.24, "text": "and"}, {"end": 830.88, "start": 830.08, "text": "output"}, {"end": 831.32, "start": 830.88, "text": "lengths"}, {"end": 831.44, "start": 831.32, "text": "in"}, {"end": 831.6, "start": 831.44, "text": "the"}, {"end": 832.16, "start": 831.6, "text": "data."}, {"end": 832.76, "start": 832.16, "text": "So"}, {"end": 832.88, "start": 832.76, "text": "this"}, {"end": 832.96, "start": 832.88, "text": "is"}, {"end": 833.88, "start": 832.96, "text": "just"}, {"end": 834.84, "start": 833.88, "text": "a"}, {"end": 836.0, "start": 834.84, "text": "systematical"}, {"end": 836.64, "start": 836.0, "text": "results"}, {"end": 836.76, "start": 836.64, "text": "of"}, {"end": 837.0, "start": 836.76, "text": "this"}, {"end": 837.6, "start": 837.0, "text": "data."}, {"end": 837.76, "start": 837.6, "text": "I"}, {"end": 838.12, "start": 837.76, "text": "think"}, {"end": 838.32, "start": 838.12, "text": "it"}, {"end": 838.56, "start": 838.32, "text": "should"}, {"end": 839.0, "start": 838.56, "text": "be"}, {"end": 839.96, "start": 839.0, "text": "more"}], "text": " variability of different time series data. For example, as we mentioned before, actually this data may have different lengths of input and output data. So we actually do not normalize it, but actually incorporate combinations of different input and output lengths in the data. So this is just a systematical results of this data. I think it should be more"}, {"chunks": [{"end": 840.52, "start": 840.0, "text": "more"}, {"end": 840.52, "start": 840.52, "text": "intuitive"}, {"end": 840.6, "start": 840.52, "text": "to"}, {"end": 841.24, "start": 840.6, "text": "normalize"}, {"end": 841.4, "start": 841.24, "text": "the"}, {"end": 841.88, "start": 841.4, "text": "results"}, {"end": 842.2, "start": 841.88, "text": "later"}, {"end": 842.52, "start": 842.2, "text": "on."}, {"end": 842.72, "start": 842.52, "text": "So"}, {"end": 843.32, "start": 842.72, "text": "there's"}, {"end": 843.56, "start": 843.32, "text": "a"}, {"end": 845.08, "start": 843.56, "text": "relevant"}, {"end": 845.4, "start": 845.08, "text": "question."}, {"end": 845.68, "start": 845.4, "text": "So"}, {"end": 845.8, "start": 845.68, "text": "you"}, {"end": 845.96, "start": 845.8, "text": "have"}, {"end": 846.32, "start": 845.96, "text": "considered"}, {"end": 846.84, "start": 846.32, "text": "multiple"}, {"end": 847.12, "start": 846.84, "text": "time"}, {"end": 847.52, "start": 847.12, "text": "series"}, {"end": 848.64, "start": 847.52, "text": "foundation"}, {"end": 849.16, "start": 848.64, "text": "models,"}, {"end": 849.72, "start": 849.16, "text": "right?"}, {"end": 850.48, "start": 849.72, "text": "So"}, {"end": 850.72, "start": 850.48, "text": "these"}, {"end": 851.24, "start": 850.72, "text": "models"}, {"end": 851.24, "start": 851.24, "text": "are"}, {"end": 851.64, "start": 851.24, "text": "trained"}, {"end": 852.04, "start": 851.64, "text": "using"}, {"end": 852.6, "start": 852.04, "text": "different"}, {"end": 852.92, "start": 852.6, "text": "scale"}, {"end": 853.36, "start": 852.92, "text": "or"}, {"end": 853.6, "start": 853.36, "text": "different"}, {"end": 854.0, "start": 853.6, "text": "volume"}, {"end": 854.08, "start": 854.0, "text": "of"}, {"end": 854.28, "start": 854.08, "text": "data,"}, {"end": 854.6, "start": 854.28, "text": "right?"}, {"end": 855.0, "start": 854.6, "text": "Have"}, {"end": 855.16, "start": 855.0, "text": "you"}, {"end": 855.36, "start": 855.16, "text": "seen"}, {"end": 855.64, "start": 855.36, "text": "any"}, {"end": 856.32, "start": 855.64, "text": "differences"}, {"end": 856.44, "start": 856.32, "text": "among"}, {"end": 857.44, "start": 856.44, "text": "them"}, {"end": 857.84, "start": 857.44, "text": "based"}, {"end": 858.28, "start": 857.84, "text": "on"}, {"end": 858.28, "start": 858.28, "text": "the"}, {"end": 858.72, "start": 858.28, "text": "volume"}, {"end": 858.92, "start": 858.72, "text": "of"}, {"end": 859.04, "start": 858.92, "text": "data"}, {"end": 859.28, "start": 859.04, "text": "they"}, {"end": 860.32, "start": 859.28, "text": "have"}, {"end": 860.72, "start": 860.32, "text": "been"}, {"end": 861.56, "start": 860.72, "text": "trained"}, {"end": 862.16, "start": 861.56, "text": "on?"}, {"end": 862.76, "start": 862.16, "text": "Yeah,"}, {"end": 863.6, "start": 862.76, "text": "that's"}, {"end": 864.0, "start": 863.6, "text": "a"}, {"end": 864.16, "start": 864.0, "text": "good"}, {"end": 864.76, "start": 864.16, "text": "question."}, {"end": 864.88, "start": 864.76, "text": "To"}, {"end": 865.28, "start": 864.88, "text": "be"}, {"end": 865.4, "start": 865.28, "text": "honest,"}, {"end": 866.0, "start": 865.4, "text": "I"}, {"end": 866.12, "start": 866.0, "text": "think"}, {"end": 866.16, "start": 866.12, "text": "we"}, {"end": 867.08, "start": 866.16, "text": "don't"}, {"end": 868.2, "start": 867.08, "text": "have"}, {"end": 868.6, "start": 868.2, "text": "a"}, {"end": 869.96, "start": 868.6, "text": "very"}], "text": " more intuitive to normalize the results later on. So there's a relevant question. So you have considered multiple time series foundation models, right? So these models are trained using different scale or different volume of data, right? Have you seen any differences among them based on the volume of data they have been trained on? Yeah, that's a good question. To be honest, I think we don't have a very"}, {"chunks": [{"end": 871.28, "start": 870.0, "text": "clear"}, {"end": 872.6, "start": 871.28, "text": "observation"}, {"end": 872.88, "start": 872.6, "text": "on"}, {"end": 873.16, "start": 872.88, "text": "this"}, {"end": 873.96, "start": 873.16, "text": "because"}, {"end": 874.12, "start": 873.96, "text": "for"}, {"end": 874.44, "start": 874.12, "text": "example,"}, {"end": 874.76, "start": 874.44, "text": "some"}, {"end": 874.84, "start": 874.76, "text": "of"}, {"end": 875.04, "start": 874.84, "text": "these"}, {"end": 875.52, "start": 875.04, "text": "models"}, {"end": 875.8, "start": 875.52, "text": "even"}, {"end": 876.24, "start": 875.8, "text": "do"}, {"end": 876.44, "start": 876.24, "text": "not"}, {"end": 877.04, "start": 876.44, "text": "expose"}, {"end": 877.68, "start": 877.04, "text": "the"}, {"end": 878.2, "start": 877.68, "text": "sources"}, {"end": 878.92, "start": 878.2, "text": "of"}, {"end": 879.56, "start": 878.92, "text": "training"}, {"end": 880.4, "start": 879.56, "text": "data"}, {"end": 880.8, "start": 880.4, "text": "they"}, {"end": 881.24, "start": 880.8, "text": "have"}, {"end": 881.76, "start": 881.24, "text": "used."}, {"end": 882.64, "start": 881.76, "text": "But"}, {"end": 882.84, "start": 882.64, "text": "in"}, {"end": 884.4, "start": 882.84, "text": "general,"}, {"end": 884.64, "start": 884.4, "text": "we"}, {"end": 885.32, "start": 884.64, "text": "can"}, {"end": 885.76, "start": 885.32, "text": "see"}, {"end": 886.64, "start": 885.76, "text": "that"}, {"end": 886.88, "start": 886.64, "text": "for"}, {"end": 887.12, "start": 886.88, "text": "seeing"}, {"end": 887.72, "start": 887.12, "text": "datasets,"}, {"end": 888.36, "start": 887.72, "text": "for"}, {"end": 889.2, "start": 888.36, "text": "example,"}, {"end": 889.84, "start": 889.2, "text": "some"}, {"end": 890.92, "start": 889.84, "text": "models"}, {"end": 891.32, "start": 890.92, "text": "have"}, {"end": 893.36, "start": 891.32, "text": "introduced"}, {"end": 894.04, "start": 893.36, "text": "the"}, {"end": 894.6, "start": 894.04, "text": "training"}, {"end": 895.08, "start": 894.6, "text": "data."}, {"end": 895.52, "start": 895.08, "text": "For"}, {"end": 896.2, "start": 895.52, "text": "seeing"}, {"end": 896.8, "start": 896.2, "text": "dataset,"}, {"end": 897.12, "start": 896.8, "text": "we"}, {"end": 897.48, "start": 897.12, "text": "found"}, {"end": 897.84, "start": 897.48, "text": "that"}, {"end": 898.2, "start": 897.84, "text": "these"}, {"end": 898.56, "start": 898.2, "text": "models"}, {"end": 899.16, "start": 898.56, "text": "perform"}, {"end": 899.96, "start": 899.16, "text": "best"}], "text": " clear observation on this because for example, some of these models even do not expose the sources of training data they have used. But in general, we can see that for seeing datasets, for example, some models have introduced the training data. For seeing dataset, we found that these models perform best"}, {"chunks": [{"end": 900.84, "start": 900.0, "text": "But"}, {"end": 902.44, "start": 900.84, "text": "for"}, {"end": 902.96, "start": 902.44, "text": "unseen"}, {"end": 903.32, "start": 902.96, "text": "datasets,"}, {"end": 903.48, "start": 903.32, "text": "I"}, {"end": 903.68, "start": 903.48, "text": "think"}, {"end": 903.92, "start": 903.68, "text": "the"}, {"end": 904.52, "start": 903.92, "text": "performance"}, {"end": 904.88, "start": 904.52, "text": "is"}, {"end": 905.72, "start": 904.88, "text": "unpredictable."}, {"end": 906.52, "start": 905.72, "text": "Yes."}, {"end": 906.92, "start": 906.52, "text": "And"}, {"end": 907.2, "start": 906.92, "text": "in"}, {"end": 907.88, "start": 907.2, "text": "general,"}, {"end": 908.04, "start": 907.88, "text": "we"}, {"end": 908.4, "start": 908.04, "text": "think"}, {"end": 908.8, "start": 908.4, "text": "actually"}, {"end": 909.24, "start": 908.8, "text": "the"}, {"end": 910.32, "start": 909.24, "text": "time"}, {"end": 911.0, "start": 910.32, "text": "GPT"}, {"end": 911.72, "start": 911.0, "text": "model"}, {"end": 912.32, "start": 911.72, "text": "actually"}, {"end": 913.0, "start": 912.32, "text": "performs,"}, {"end": 913.8, "start": 913.0, "text": "I"}, {"end": 914.44, "start": 913.8, "text": "think,"}, {"end": 915.72, "start": 914.44, "text": "relatively"}, {"end": 916.56, "start": 915.72, "text": "better"}, {"end": 917.36, "start": 916.56, "text": "among"}, {"end": 917.8, "start": 917.36, "text": "these"}, {"end": 918.48, "start": 917.8, "text": "models"}, {"end": 918.76, "start": 918.48, "text": "because"}, {"end": 918.92, "start": 918.76, "text": "they"}, {"end": 919.48, "start": 918.92, "text": "can"}, {"end": 919.88, "start": 919.48, "text": "deal"}, {"end": 920.2, "start": 919.88, "text": "in"}, {"end": 921.0, "start": 920.2, "text": "ways,"}, {"end": 921.08, "start": 921.0, "text": "I"}, {"end": 921.68, "start": 921.08, "text": "think"}, {"end": 921.96, "start": 921.68, "text": "they"}, {"end": 922.12, "start": 921.96, "text": "can"}, {"end": 922.76, "start": 922.12, "text": "deal"}, {"end": 922.92, "start": 922.76, "text": "in"}, {"end": 923.36, "start": 922.92, "text": "with"}, {"end": 924.4, "start": 923.36, "text": "multiple"}, {"end": 924.96, "start": 924.4, "text": "variables,"}, {"end": 926.0, "start": 924.96, "text": "multiple"}, {"end": 926.96, "start": 926.0, "text": "attributes."}, {"end": 928.2, "start": 926.96, "text": "And"}, {"end": 928.76, "start": 928.2, "text": "as"}, {"end": 929.2, "start": 928.76, "text": "shown"}, {"end": 929.24, "start": 929.2, "text": "in"}, {"end": 929.96, "start": 929.24, "text": "this,"}], "text": " But for unseen datasets, I think the performance is unpredictable. Yes. And in general, we think actually the time GPT model actually performs, I think, relatively better among these models because they can deal in ways, I think they can deal in with multiple variables, multiple attributes. And as shown in this,"}, {"chunks": [{"end": 930.28, "start": 930.0, "text": "this"}, {"end": 931.0, "start": 930.28, "text": "table,"}, {"end": 931.44, "start": 931.0, "text": "the"}, {"end": 931.72, "start": 931.44, "text": "time"}, {"end": 931.8, "start": 931.72, "text": "GPT"}, {"end": 931.88, "start": 931.8, "text": "model"}, {"end": 932.36, "start": 931.88, "text": "can"}, {"end": 932.64, "start": 932.36, "text": "deal"}, {"end": 932.92, "start": 932.64, "text": "in"}, {"end": 933.28, "start": 932.92, "text": "with"}, {"end": 933.56, "start": 933.28, "text": "multiple"}, {"end": 934.12, "start": 933.56, "text": "variants"}, {"end": 934.28, "start": 934.12, "text": "as"}, {"end": 934.4, "start": 934.28, "text": "well"}, {"end": 935.08, "start": 934.4, "text": "as"}, {"end": 936.08, "start": 935.08, "text": "irregular"}, {"end": 936.32, "start": 936.08, "text": "time"}, {"end": 936.8, "start": 936.32, "text": "series."}, {"end": 937.12, "start": 936.8, "text": "So"}, {"end": 937.24, "start": 937.12, "text": "I"}, {"end": 937.52, "start": 937.24, "text": "think"}, {"end": 938.04, "start": 937.52, "text": "currently"}, {"end": 938.32, "start": 938.04, "text": "is"}, {"end": 938.76, "start": 938.32, "text": "a"}, {"end": 939.16, "start": 938.76, "text": "relatively"}, {"end": 939.52, "start": 939.16, "text": "better"}, {"end": 940.4, "start": 939.52, "text": "model."}, {"end": 940.76, "start": 940.4, "text": "Thank"}, {"end": 941.6, "start": 940.76, "text": "you."}, {"end": 942.88, "start": 941.6, "text": "Thank"}, {"end": 943.32, "start": 942.88, "text": "you."}], "text": " this table, the time GPT model can deal in with multiple variants as well as irregular time series. So I think currently is a relatively better model. Thank you. Thank you."}]}}